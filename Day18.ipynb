{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c680f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a863181",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "PCA stands for \"principal components analysis\".\n",
    "\n",
    "The \"principal components\" in PCA are the axes of covariation. Intuition: if you look at a pairplot, in what direction (if any) do you see the variables pointing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd89562",
   "metadata": {},
   "source": [
    "The idea behind PCA is:\n",
    "* find the components (the intrinsic axes of variation)\n",
    "* order them from largest to smallest\n",
    "* drop the smallest ones\n",
    "\n",
    "This gives a data set with fewer variables, but that still has most of the information of the full dataset. Note that this type of projection does *not drop data variables*, instead it drops variation between data variables.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7828258",
   "metadata": {},
   "source": [
    "We can do this using matrix math!\n",
    "* Rotate so the principal coordinates become coordinate axes (translation then rotation), then \n",
    "* drop the lesser ones, then \n",
    "* reverse the rotation and translation: $$A_{reconstruct} = (P@A_c^T)^T + \\mu = A_c @ P^T + \\mu$$\n",
    "    \n",
    "The rotation matrix is the *eigenvectors* of the covariance matrix. The eigenvectors tell us the direction of the principal components. The eigenvalues tell us the amount of variation in each principal coordinate direction.\n",
    "\n",
    "(For more on eigenvalues and eigenvectors, see Linear Algebra or https://www.mathsisfun.com/algebra/eigenvalue.html)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed7100f1",
   "metadata": {},
   "source": [
    "The eigenvectors are *orthonormal*. What does that mean?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53e774a1",
   "metadata": {},
   "source": [
    "So the steps to calculate PCA are:\n",
    "\n",
    "0. (If appropriate) normalize the variables to be in the range 0-1\n",
    "1. Center the data\n",
    "2. Compute the covariance matrix\n",
    "3. Compute the eigenvectors and eigenvalues; the eigenvectors tell us the direction of variance, and the eigenvalues tell us the amount of variance\n",
    "4. Get an ordering over the eigenvalues\n",
    "5. Sort the eigenvalues and eigenvectors accordingly\n",
    "6. Compute the proportional variance (how much bigger?) accounted for by each principal component\n",
    "7. Compute the cumulative sum of the proportional variance (tells us how many eigenvectors we need to explain a desired amount of variance)\n",
    "8. Examine the principal components. Select v' of them.\n",
    "9. Project the data into PCA space\n",
    "10. Reconstruct the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57a92b0f",
   "metadata": {},
   "source": [
    "Let's do it on a small dataset so we can see what's going on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 4],[2, 3], [3, 2], [4, 1.0]])\n",
    "print(data)\n",
    "columns = ['x,', 'y']\n",
    "\n",
    "plt.scatter(x = data[:, 0], y=data[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45aeee46",
   "metadata": {},
   "source": [
    "First, center the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8888154",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_data = data - np.mean(data, axis=0)\n",
    "print(centered_data.shape)\n",
    "plt.scatter(x = centered_data[:, 0], y=centered_data[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b90dc9cf",
   "metadata": {},
   "source": [
    "Second, compute the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = (centered_data.T @ centered_data) / (data.shape[0] - 1)\n",
    "print(covariance_matrix.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee3bb43e",
   "metadata": {},
   "source": [
    "Third, get the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(evals, evectors) = np.linalg.eig(covariance_matrix)\n",
    "print(evals.shape)\n",
    "print(evectors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db67cf29",
   "metadata": {},
   "source": [
    "*Let's pause and look up this eig function. Do the eigenvectors run along the rows or columns of the returned matrix?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe1af1d8",
   "metadata": {},
   "source": [
    "Fourth, get an ordering over the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an ordering over the eigenvalues\n",
    "\n",
    "evals_order = np.argsort(evals)[::-1]\n",
    "print(evals_order)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc87131d",
   "metadata": {},
   "source": [
    "Fifth, sort the eigenvalues and eigenvectors according to that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_sorted = evals[evals_order]\n",
    "for e in evals_sorted:\n",
    "    print(e)\n",
    "\n",
    "evectors_sorted = evectors[:, evals_order]\n",
    "print(evectors_sorted.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ed61f7e",
   "metadata": {},
   "source": [
    "Sixth, calculate the proportional variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_sum = np.sum(evals_sorted)\n",
    "ps = [eval / evals_sum for eval in evals_sorted]\n",
    "print(ps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06d526e3",
   "metadata": {},
   "source": [
    "Seventh, calculate the cumulative sum of the proportional variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(ps)):\n",
    "    c = c + ps[i]\n",
    "    print(i, ps[i], c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d970f88a",
   "metadata": {},
   "source": [
    "Eighth, examine the principal components. Select the top $n$ of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566afbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evectors_sorted)\n",
    "\n",
    "v = np.array([evectors_sorted[:, 0]]).T\n",
    "print(v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48766931",
   "metadata": {},
   "source": [
    "Ninth, project the data into PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1476827",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_data = centered_data@v\n",
    "print(projected_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66b9b743",
   "metadata": {},
   "source": [
    "Tenth, reconstruct the data with only the chosen principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = projected_data@v.T + np.mean(data, axis=0)\n",
    "print(reconstructed_data)\n",
    "plt.scatter(x = reconstructed_data[:, 0], y=reconstructed_data[:, 1], color=\"black\")\n",
    "plt.scatter(x = data[:, 0], y=data[:, 1], color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bbc7513",
   "metadata": {},
   "source": [
    "If we do all this, then:\n",
    "* what does the data look like in \"PCA space\"?\n",
    "* what does it look like projected back?\n",
    "* how does a regression fit on the PC transformed data compare with one fit on the original data?\n",
    "* What if all the points were on a line?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7687f07",
   "metadata": {},
   "source": [
    "# PCA on our data\n",
    "\n",
    "First, load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will be our columns\n",
    "columns = [\"price\", \"year\", \"manufacturer\", \"model\", \"condition\", \"fuel\", \"odometer\", \"title_status\", \"transmission\"]\n",
    "# this will contain our converters\n",
    "colValues = {}\n",
    "\n",
    "# first we load our data as strings so we can define the converters\n",
    "data = np.array(np.genfromtxt('data/vehicles.csv', delimiter=',', usecols=(1,2,3,4,5,7,8,9,11), skip_header=1, dtype=str, encoding='utf-8'))  \n",
    "\n",
    "# make a list of the unique values in each column of our data\n",
    "for colIndex in range(data.shape[1]):\n",
    "    colValues[colIndex] = np.unique(data[:, colIndex]).tolist()\n",
    "\n",
    "# fix up some of these ones we know are ordered\n",
    "colValues[columns.index('condition')] = ['new', 'like new', 'excellent', 'good', 'fair', 'salvage']\n",
    "colValues[columns.index('title_status')] = ['clean', 'lien', 'rebuilt', 'salvage', 'parts only', 'missing']\n",
    "\n",
    "# map values to their indices in the list of unique values\n",
    "def converter(x, colIndex):\n",
    "    return colValues[colIndex].index(x)\n",
    "\n",
    "data = np.array(np.genfromtxt('data/vehicles.csv', delimiter=',', usecols=(1,2,3,4,5,7,8,9,11), converters={3: lambda x: converter(x, 2), 4: lambda x: converter(x, 3), 5: lambda x: converter(x, 4), 7: lambda x: converter(x,5), 9: lambda x: converter(x, 7), 11: lambda x: converter(x, 8)}, skip_header=1, dtype=int, encoding='utf-8'))  \n",
    "print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d1e2c21",
   "metadata": {},
   "source": [
    "Split it into train and test. Split off the dependent variable from each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ae602",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[:, 1].argsort()]\n",
    "\n",
    "(train, test) = np.split(data, [int(len(data) / 10 * 8)])\n",
    "trainx = train[:, 1:]\n",
    "trainy = train[:, 0]\n",
    "testx = test[:, 1:]\n",
    "testy = test[:, 0]\n",
    "print(trainx.shape, testx.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b722ab",
   "metadata": {},
   "source": [
    "Second, fit PCA using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68deb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do it on our big dataset!\n",
    "import scipy as sp\n",
    "\n",
    "# center\n",
    "centered_train = trainx - np.mean(trainx, axis=0)\n",
    "print(\"centered train: \", centered_train.shape)\n",
    "\n",
    "# covariance\n",
    "covariance_matrix = (centered_train.T @ centered_train) / (centered_train.shape[0] - 1)\n",
    "print(\"covariance matrix: \", covariance_matrix.shape)\n",
    "\n",
    "# svd\n",
    "(evals, evectors) = np.linalg.eig(covariance_matrix)\n",
    "print(\"eigenvalues, eigenvectors: \", evals.shape, evectors.shape)\n",
    "\n",
    "# sort\n",
    "evals_order = np.argsort(evals)[::-1]\n",
    "evals_sorted = evals[evals_order]\n",
    "evectors_sorted = evectors[:, evals_order]\n",
    "print(\"sorted eigenvalues\")\n",
    "for e in evals_sorted:\n",
    "    print(e)\n",
    "\n",
    "# proportional variance\n",
    "evals_sum = np.sum(evals_sorted)\n",
    "ps = [e / evals_sum for e in evals_sorted]\n",
    "\n",
    "# cumulative sum of proportional variance\n",
    "print(\"cum sum prop var\")\n",
    "c = 0\n",
    "for i in range(len(ps)):\n",
    "    c = c + ps[i]\n",
    "    print(i, ps[i], c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09473580",
   "metadata": {},
   "source": [
    "Figure out how many eigenvectors to keep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v with two\n",
    "v = evectors_sorted[np.ix_(np.arange(evectors_sorted.shape[0]), [0, 1])]\n",
    "print(\"v\")\n",
    "print(v.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad8f7524",
   "metadata": {},
   "source": [
    "Project the training data and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project into PCA space\n",
    "projected_train = centered_train@v\n",
    "print(\"projected train: \", projected_train.shape)\n",
    "\n",
    "# center\n",
    "centered_test = testx - np.mean(testx, axis=0)\n",
    "print(\"centered test: \", centered_test.shape)\n",
    "\n",
    "# project into PCA space\n",
    "projected_test = centered_test@v\n",
    "print(\"projected test: \", projected_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dfdc168",
   "metadata": {},
   "source": [
    "## Linear regression on the original data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d22f1e64",
   "metadata": {},
   "source": [
    "This code comes directly from day 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defcd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sp_la\n",
    "\n",
    "# x a matrix of multiple independent variables\n",
    "# poly -> polys, a matrix of multiple polynomial degrees for each column in x in order\n",
    "def makePoly(x, polys):\n",
    "    # make an empty array of size A\n",
    "    A = np.zeros([x.shape[0], np.sum(polys)+1])\n",
    "    # left most column of 1s for the intercept\n",
    "    # notice this is also a third way to get that leading column of ones!\n",
    "    A[:, 0] = np.squeeze(x[:, 0]**0)\n",
    "    k = 1\n",
    "    # for each variable\n",
    "    for (j, poly) in enumerate(polys):\n",
    "        # for up to and including! poly\n",
    "        for i in range(1, poly+1):\n",
    "            A[:, k] = np.squeeze(x[:, j]**i)\n",
    "            k += 1\n",
    "    return A\n",
    "\n",
    "def fit(data, independent, dependent, polys):\n",
    "    # This is our independent variable, just one for now\n",
    "    x = data[np.ix_(np.arange(data.shape[0]), independent)]\n",
    "\n",
    "    # We add the polynomials, and a column of 1s for the intercept\n",
    "    A = makePoly(x, polys)\n",
    "\n",
    "    # This is the dependent variable \n",
    "    y = data[:, dependent]\n",
    "\n",
    "    # This is the regression coefficients that were fit, plus some other results\n",
    "    # We use _ when we don't want to remember something a function returns\n",
    "    c, _, _, _ = sp_la.lstsq(A, y)\n",
    "    return c\n",
    "\n",
    "def predict(data, independent, polys, c):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[np.ix_(np.arange(data.shape[0]), independent)]\n",
    "\n",
    "    # We add the polynomials, and a column of 1s for the intercept\n",
    "    A = makePoly(x, polys)\n",
    "\n",
    "    return np.dot(A, c)\n",
    "\n",
    "def msse(y, yhat):\n",
    "    r = (np.square(y - yhat)).mean()\n",
    "    return r\n",
    "\n",
    "def rsquared(y, yhat):\n",
    "    if len(y) != len(yhat):\n",
    "        print(\"Need y and yhat to be the same length!\")\n",
    "        return 0\n",
    "    return 1 - (((y - yhat)**2).sum() / ((y - y.mean())**2).sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "addbaba1",
   "metadata": {},
   "source": [
    "Fit a multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use all our independent variables\n",
    "variableset = list(range(trainx.shape[1]))\n",
    "\n",
    "# all with polynomial 1\n",
    "polys = [1 for x in range(len(variableset))]\n",
    "c = fit(trainx, list(variableset), 0, polys)\n",
    "# calculate MSSE and R^2\n",
    "print(msse(trainy, predict(trainx, variableset, polys, c)), \n",
    "                        rsquared(testy, predict(testx, variableset, polys, c)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "197e47d0",
   "metadata": {},
   "source": [
    "## Linear regression on the projected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d816bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use all our independent variables\n",
    "variableset = list(range(projected_train.shape[1]))\n",
    "\n",
    "# all with polynomial 1\n",
    "polys = [1 for x in range(len(variableset))]\n",
    "c = fit(projected_train, list(variableset), 0, polys)\n",
    "# calculate MSSE and R^2\n",
    "print(msse(trainy, predict(projected_train, variableset, polys, c)), \n",
    "                        rsquared(testy, predict(projected_test, variableset, polys, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2af3e",
   "metadata": {},
   "source": [
    "Resources:\n",
    "* https://plotly.com/python/pca-visualization/\n",
    "* https://wendynavarrete.com/principal-component-analysis-with-numpy/\n",
    "* https://dev.to/akaame/implementing-simple-pca-using-numpy-3k0a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
