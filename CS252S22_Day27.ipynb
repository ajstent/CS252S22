{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70007ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f10b3a",
   "metadata": {},
   "source": [
    "## Bayes' Rule reviewed \n",
    "\n",
    "$P(Y|X) = \\frac{P(Y)*P(X|Y)}{P(X)}$. \n",
    "* $P(Y|X)$ is the *posterior*\n",
    "* $P(Y)$ is the *prior*\n",
    "* $P(X|Y)$ is the *likelihood*\n",
    "* $P(X)$ is the *evidence* (or *normalization*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c4a9b",
   "metadata": {},
   "source": [
    "## Fitting and predicting using Naive Bayes\n",
    "\n",
    "Let's imagine I have an infinite bag of M&Ms. Some of them are peanut, some raisin and some regular. I only like peanut M&Ms. The thing is, I'm in a dark room so I can only guess the type of the M&M by feel. I repeatedly reach into the bag, grab one M&M and then either eat it or do not eat it. This gives the dataset below:\n",
    "\n",
    "| Candy | Outcome |\n",
    "| ----- | ---- |\n",
    "| peanut M&M | ate it |\n",
    "| peanut M&M | ate it |\n",
    "| peanut M&M | ate it |\n",
    "| raisin M&M | did not eat it |\n",
    "| raisin M&M | ate it |\n",
    "| regular M&M | did not eat it |\n",
    "| peanut M&M | did not eat it |\n",
    "| regular M&M | did not eat it |\n",
    "| raisin M&M | did not eat it |\n",
    "| raisin M&M | did not eat it |\n",
    "\n",
    "In code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2948b",
   "metadata": {},
   "source": [
    "Side note: we typically convert qualitative values to numbers for machine learning; it enables us to use all the power of numpy, at some cost in readability to humans. I'm not going to do this today, for readability to us, but on Friday we'll be back to 'numeric' representation of features.\n",
    "\n",
    "We want to fit a model that will tell us the probability that we ate it (or did not eat it) given the type of candy it is. We can do that by calculating:\n",
    "* The prior that we ate it (or did not eat it)\n",
    "* The likelihood of the type of candy given that we ate it (or did not eat it) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce0c4f",
   "metadata": {},
   "source": [
    "## What if I have multiple independent variables?\n",
    "\n",
    "It's fairly obvious that I *must* be making my eat/don't eat decisions based on more than just the candy type. Just look at the test data! \n",
    "\n",
    "Let's take the same training data as before, but add one more feature: the length of each piece of candy. \n",
    "\n",
    "Because numpy won't let me have arrays of heterogeneous types, I'm going to express length and width as 's', 'm' or 'l'.\n",
    "\n",
    "| Candy | Length | Outcome |\n",
    "| ----- | ---- | --- |\n",
    "| peanut M&M | l | ate it |\n",
    "| peanut M&M | l | ate it |\n",
    "| peanut M&M | l | ate it |\n",
    "| raisin M&M | m | did not eat it |\n",
    "| raisin M&M | l | ate it |\n",
    "| regular M&M | s | did not eat it |\n",
    "| peanut M&M | m | did not eat it |\n",
    "| regular M&M | s | did not eat it |\n",
    "| raisin M&M | s | did not eat it |\n",
    "| raisin M&M | s | did not eat it |\n",
    "\n",
    "In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e60098a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['peanut M&M' 'l' 'ate it']\n",
      " ['peanut M&M' 'l' 'ate it']\n",
      " ['peanut M&M' 'l' 'ate it']\n",
      " ['raisin M&M' 'm' 'did not eat it']\n",
      " ['raisin M&M' 'l' 'ate it']\n",
      " ['regular M&M' 's' 'did not eat it']\n",
      " ['peanut M&M' 'm' 'did not eat it']\n",
      " ['regular M&M' 's' 'did not eat it']\n",
      " ['raisin M&M' 's' 'did not eat it']\n",
      " ['raisin M&M' 'm' 'did not eat it']]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([\n",
    "    ['peanut M&M', 'l', 'ate it'], \n",
    "    ['peanut M&M', 'l', 'ate it'], \n",
    "    ['peanut M&M', 'l', 'ate it'], \n",
    "    ['raisin M&M', 'm', 'did not eat it'], \n",
    "    ['raisin M&M', 'l', 'ate it'], \n",
    "    ['regular M&M', 's', 'did not eat it'], \n",
    "    ['peanut M&M', 'm', 'did not eat it'], \n",
    "    ['regular M&M', 's', 'did not eat it'], \n",
    "    ['raisin M&M', 's', 'did not eat it'], \n",
    "    ['raisin M&M', 'm', 'did not eat it']])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69cd989",
   "metadata": {},
   "source": [
    "Looking at the data, is the length feature independent of the type feature?\n",
    "* How many large, medium and small peanut M&Ms are there?\n",
    "* How many large, medium and small raisin M&Ms are there?\n",
    "* How many large, medium and small regular M&Ms are there?\n",
    "\n",
    "### Conditional independence\n",
    "\n",
    "When we fit a Naive Bayes model across multiple independent features, we assume those features are *conditionally independent*, given $Y$. In other words, the effect of the value of a feature  on the label is independent of the values of other features.\n",
    "\n",
    "The Naive Bayes formula in this case, where $X = {x_1, x_2, ...}$ looks like:\n",
    "$P(Y|X) = argmax_Y P(Y)*P(X|Y) = argmax_Y P(Y)*\\prod_i{P(x_i|Y)}$.\n",
    "\n",
    "We can do the product of $P(x_i|Y)$ because of this *conditional independence*. This *conditional independence* assumption is the \"naive\" in Naive Bayes.\n",
    "\n",
    "Even if the independent variables aren't really conditionally independent, Naive Bayes is still a surprisingly strong baseline model for many tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffabd86",
   "metadata": {},
   "source": [
    "### Missing feature values\n",
    "\n",
    "Let's make a table of counts, like before:\n",
    "\n",
    "| Outcome | Peanut M&M | Regular M&M | Raisin M&M | l | m | s |\n",
    "| -------- | ------- | ---------- | ------------ | -- | -- | -- |\n",
    "| Ate it         | 3 | 0 | 1 | 4 | 0 | 0 |\n",
    "| Did not eat it | 1 | 2 | 3 | 0 | 2 | 4 |\n",
    "| Total |  4 | 2 | 4 | 4 | 2 | 4 |\n",
    "\n",
    "Ok, the fact that there are 0s in this table is a problem. It means that if we ever *do* (during testing or inference) see, for example, a small peanut M&M, $P(small | ate it)$ will \"zero out\" the total even though the peanutness should lend towards edibility. So we use __Laplace smoothing__: for $x_i \\in X$:\n",
    "* instead of $P(Y|x_i) \\sim \\frac{|x_i \\& Y|}{|X|}$, \n",
    "* we use $P(Y|x_i) \\sim \\frac{|x_i \\& Y|+1}{|X| + |Y|}$. \n",
    "\n",
    "In this way, there's some (small!) likelihood for every value of each independent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec8ed9",
   "metadata": {},
   "source": [
    "__Fit__\n",
    "\n",
    "* Calculate the prior for *ate it* and the prior for *did not eat it*: $P(ate it) = 4 / 10$; $P(did not eat it) = 6 / 10$\n",
    "\n",
    "* Calculate the likelihood of each of *ate it* and *did not eat it* given:\n",
    "  * *peanut M&M*, *regular M&M* and *raisin M&M*. For example, the likelihood of *ate it* given *peanut M&M* = (3 (peanut M&Ms that were eaten) + 1 (smoothing)) / (4 (peanut M&M) + 3 (values for peanuts))\n",
    "  * *s*, *m* and *l*\n",
    "  \n",
    "| Y | Peanut M&M | Regular M&M | Raisin M&M | l | m | s |\n",
    "| -------- | ------- | ---------- | ------------ | -- | -- | -- |\n",
    "| Ate it         | 4/6 | 1/4 | 2/6 | 5/6  |  1/4 | 1/6 |\n",
    "| Did not eat it | 2/6 | 3/4 | 4/6 | 1/6 | 3/4 | 5/6 |\n",
    "\n",
    "Store both sets of values.\n",
    "\n",
    "In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9936c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peanut M&M 3 4 2\n",
      "raisin M&M 1 4 2\n",
      "regular M&M 0 2 2\n",
      "l 4 0 2\n",
      "m 0 0 2\n",
      "s 0 0 2\n",
      "peanut M&M 1 4 2\n",
      "raisin M&M 3 4 2\n",
      "regular M&M 2 2 2\n",
      "l 0 0 2\n",
      "m 3 0 2\n",
      "s 3 0 2\n",
      "{'ate it': {'peanut M&M': 0.6666666666666666, 'raisin M&M': 0.3333333333333333, 'regular M&M': 0.25, 'l': 0.8333333333333334, 'm': 0.2, 's': 0.2}, 'did not eat it': {'peanut M&M': 0.3333333333333333, 'raisin M&M': 0.6666666666666666, 'regular M&M': 0.75, 'l': 0.16666666666666666, 'm': 0.8, 's': 0.8}} {'ate it': 0.4, 'did not eat it': 0.6}\n"
     ]
    }
   ],
   "source": [
    "def fit(data):\n",
    "    likelihoods = {}\n",
    "    cats = sorted(np.unique(data[:, -1]))\n",
    "    all_values = np.unique(data[:, :-1])\n",
    "    for cat in cats:\n",
    "        likelihoods[cat] = {}\n",
    "        for feature in range(data.shape[1]-1):\n",
    "            values = sorted(np.unique(data[:, feature]))\n",
    "            for value in values:\n",
    "                print(value, len(data[np.where((data[:, feature] == value) & (data[:, -1] == cat))]), len(data[np.where(data[:, 0] == value)]), len(cats))\n",
    "                likelihoods[cat][value] = (len(data[np.where((data[:, feature] == value) & (data[:, -1] == cat))]) + 1) / (len(data[np.where(data[:, feature] == value)]) + len(cats))\n",
    " \n",
    "    priors = {cat : len(data[np.where(data[:, -1] == cat)]) / len(data) for cat in cats}\n",
    "    return likelihoods, priors\n",
    "\n",
    "likelihoods, priors = fit(data)\n",
    "print(likelihoods, priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36dac31",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Given a new observation, *large raisin M&M*, what is my most likely behavior?\n",
    "\n",
    "* Compare $P(ate it|large, raisin M\\&M)$ and $P(did not eat it|large, raisin M\\&M)$. \n",
    "\n",
    "Calculate $argmax_Y P(Y)*\\prod_i{P(x_i|Y)}$:\n",
    "* ate it: \n",
    "* did not eat it:\n",
    "\n",
    "In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8c12b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(datum, likelihoods, priors):\n",
    "    res = []\n",
    "    for cat in likelihoods:\n",
    "        product = 1\n",
    "        for value in datum:\n",
    "            try:\n",
    "                likelihood = likelihoods[cat][value]\n",
    "            except:\n",
    "                print(\"feature value \" + value + \" is not in likelihoods, returning most frequent category!\")\n",
    "                likelihood = 1\n",
    "            product = product*likelihood\n",
    "        res.append(priors[cat]*product)\n",
    "    return list(likelihoods.keys())[np.argmax(res)]\n",
    "\n",
    "def predict(data, likelihoods, priors):\n",
    "    return np.array([predict_one(datum, likelihoods, priors) for datum in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1e76b",
   "metadata": {},
   "source": [
    "### Score\n",
    "\n",
    "Am I doing better with one more feature? Let's see! Here's my augmented test data:\n",
    "\n",
    "| Candy | Length | Outcome |\n",
    "| ----- | ---- | --- |\n",
    "| peanut M&M | s | did not eat it |\n",
    "| peanut M&M | l | ate it |\n",
    "| raisin M&M | s | did not eat it |\n",
    "| raisin M&M | l | ate it |\n",
    "| regular M&M | m | did not eat it |\n",
    "\n",
    "| Y | x1 | x2| P(ate it)\\*P(ate it\\|x1)\\*P(ate it\\|x2) | P(did not eat it)\\*P(did not eat it\\|x1)\\*P(did not eat it\\|x2) | Yhat |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| did not eat it | peanut M&M | s | 16/490 | 60 / 810  | did not eat it  |\n",
    "| ate it | peanut M&M | l | 80/490 | 12/810 | ate it |\n",
    "| did not eat it | raisin M&M | s | 8/490 | 120/810 | did not eat it | \n",
    "| ate it | raisin M&M | l | 40/490 | 24/810 | ate it | \n",
    "| did not eat it | regular M&M | m | 4/490 | 54/810  | did not eat it |\n",
    "\n",
    "Based on this test data:\n",
    "* What is the accuracy?\n",
    "* What is the confusion matrix?\n",
    "\n",
    "|  | ate it | did not eat it |\n",
    "| -- | --- | ---- |\n",
    "| ate it | | |\n",
    "| did not eat it | | |\n",
    "\n",
    "In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef4991ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['peanut M&M' 's' 'did not eat it']\n",
      " ['peanut M&M' 'l' 'ate it']\n",
      " ['raisin M&M' 's' 'did not eat it']\n",
      " ['raisin M&M' 'l' 'ate it']\n",
      " ['regular M&M' 'm' 'did not eat it']]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([['peanut M&M', 's', 'did not eat it'], ['peanut M&M', 'l', 'ate it'], ['raisin M&M', 's', 'did not eat it'], ['raisin M&M', 'l', 'ate it'], ['regular M&M', 'm', 'did not eat it']])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc438dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['did not eat it' 'ate it' 'did not eat it' 'ate it' 'did not eat it'] ['did not eat it' 'ate it' 'did not eat it' 'ate it' 'did not eat it']\n"
     ]
    }
   ],
   "source": [
    "yhat = predict(test[:, :-1], likelihoods, priors)\n",
    "print(test[:, -1], yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22576e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These come directly from day 24\n",
    "\n",
    "def accuracy(y, yhat):\n",
    "    assert len(y) == len(yhat)\n",
    "    diffs = y == yhat\n",
    "    vals, counts = np.unique(diffs, return_counts=True)\n",
    "    return counts[np.where(vals == True)] / (np.sum(counts))\n",
    "    \n",
    "def confusion_matrix(y, yhat, cats):\n",
    "    \"Thanks to https://stackoverflow.com/questions/2148543/how-to-write-a-confusion-matrix-in-python\"\n",
    "    assert len(y) == len(yhat)\n",
    "    result = np.zeros((len(cats), len(cats)))\n",
    "    for i in range(len(y)):\n",
    "        result[cats.index(y[i])][cats.index(yhat[i])] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88d62322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "['ate it', 'did not eat it'] [[2. 0.]\n",
      " [0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(test[:, -1], yhat))\n",
    "print(cats, confusion_matrix(test[:, -1], yhat, cats))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
