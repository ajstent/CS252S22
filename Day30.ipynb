{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0e7ca52",
   "metadata": {},
   "source": [
    "# The Second Goal For Today!\n",
    "\n",
    "Understand how PCA can influence naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6243b190",
   "metadata": {},
   "source": [
    "# Load and Look at Your Data\n",
    "\n",
    "The data set we wil be analyzing is the dataset of car logos from https://github.com/GeneralBlockchain/vehicle-logos-dataset. I converted each logo to greyscale and downscaled them to a consistent size. I also converted the dependent variable (manufacturer name) to an int; it is the last column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8571c1f",
   "metadata": {},
   "source": [
    "First we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca359103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = np.array(np.genfromtxt('data/logos.csv', delimiter=',', dtype=int))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68a5a5ca",
   "metadata": {},
   "source": [
    "Then we get summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    return pd.DataFrame([data.min(axis=0), data.max(axis=0), data.mean(axis=0), data.std(axis=0)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef7fcc85",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "If we are doing supervised machine learning, we split the data into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# split the data into train and test\n",
    "(train, test) = np.split(data, [int(len(data) / 10 * 8)])\n",
    "print(\"train, test: \", train.shape, test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "283ad7b8",
   "metadata": {},
   "source": [
    "Strip off the dependent variable (the labels, the classes). Let's go with trying to predict the car's **drive train**. That's the last variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[:, -1]\n",
    "x_train = train[:, 0:-1]\n",
    "y_test = test[:, -1]\n",
    "x_test = test[:, 0:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0695d83",
   "metadata": {},
   "source": [
    "# PCA Review\n",
    "\n",
    "This code for PCA comes from day 19; I just put it into functions.\n",
    "\n",
    "This code you can use as a **tool**.\n",
    "\n",
    "**If you are using separate training and test data, you want to project both training and test data using eigenvectors calculated on the _training data_.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce21b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pca(data):\n",
    "    # center data\n",
    "    centered_data = data - np.mean(data, axis=0)\n",
    "    # covariance matrix\n",
    "    covariance_matrix = (centered_data.T @ centered_data) / (data.shape[0] - 1)\n",
    "    # singular value decomposition\n",
    "    evals, evectors = scipy.linalg.eigh(covariance_matrix)\n",
    "    # sort eigenvals, eigenvecs\n",
    "    order = np.argsort(evals)[::-1]\n",
    "    eigenvals_sorted = evals[order]\n",
    "    eigenvecs_sorted = evectors[:, order]\n",
    "    return centered_data, covariance_matrix, eigenvals_sorted, eigenvecs_sorted\n",
    "\n",
    "def plot_covariance_matrix(covariance_matrix):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    sns.heatmap(pd.DataFrame(covariance_matrix), annot=False, cmap='PuOr')\n",
    "    plt.show()\n",
    "\n",
    "def plot_eigenvectors(eigenvecs_sorted):\n",
    "    fig = plt.figure(figsize=(14,3))\n",
    "    sns.heatmap(pd.DataFrame(eigenvecs_sorted[:, 0:21].T), \n",
    "                annot=False, cmap='coolwarm',\n",
    "               vmin=-0.5,vmax=0.5)\n",
    "    plt.ylabel(\"Ranked Eigenvalue\")\n",
    "    plt.xlabel(\"Eigenvector Components\")\n",
    "    plt.show()\n",
    "\n",
    "def get_proportional_variances(eigenvals_sorted):\n",
    "    sum = np.sum(eigenvals_sorted)\n",
    "    proportional_variances = np.array([eigenvalue / sum for eigenvalue in eigenvals_sorted])\n",
    "    cumulative_sum = np.cumsum(proportional_variances)\n",
    "    return proportional_variances, cumulative_sum\n",
    "\n",
    "def scree_graph(proportional_variances):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(proportional_variances)), proportional_variances, alpha=0.5, align='center',\n",
    "            label='Proportional variance')\n",
    "    plt.ylabel('Proportional variance ratio')\n",
    "    plt.xlabel('Ranked Principal Components')\n",
    "    plt.title(\"Scree Graph\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def elbow_plot(cumulative_sum):\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(cumulative_sum)\n",
    "    ax1.set_ylim([0,1.0])\n",
    "    ax1.set_xlabel('Number of Principal Components')\n",
    "    ax1.set_ylabel('Cumulative explained variance')\n",
    "    ax1.set_title('Elbow Plot')\n",
    "    plt.show()\n",
    "\n",
    "def fit_pca(centered_data, eigenvecs_sorted, number_to_keep):\n",
    "    v = eigenvecs_sorted[:, :number_to_keep]\n",
    "    projected_data = centered_data@v\n",
    "    return projected_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f068493",
   "metadata": {},
   "source": [
    "Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1912f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_train, covariance_matrix, eigenvals_sorted, eigenvecs_sorted = prep_pca(x_train)\n",
    "proportional_variances, cumulative_sum = get_proportional_variances(eigenvals_sorted)\n",
    "elbow_plot(cumulative_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1376501",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_train = fit_pca(centered_train, eigenvecs_sorted, 200)\n",
    "centered_test = x_test - np.mean(x_train, axis=0)\n",
    "projected_test = fit_pca(centered_test, eigenvecs_sorted, 200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad0b841e",
   "metadata": {},
   "source": [
    "# Naive Bayes with and without PCA first\n",
    "\n",
    "The independent variables for this dataset are quantitative, so we can't use the very naive implementation of naive Bayes we've just made. Instead, I'm going to use a Gaussian NB implementation from scikit-learn, which can handle independent variables that are quantitative.\n",
    "\n",
    "But first, I copy over the definition of accuracy from day 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def accuracy(y, yhat):\n",
    "    assert len(y) == len(yhat)\n",
    "    diffs = y == yhat\n",
    "    vals, counts = np.unique(diffs, return_counts=True)\n",
    "    return counts[np.where(vals == True)] / (np.sum(counts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a20fef0",
   "metadata": {},
   "source": [
    "## NB without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beef829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acb8fb08",
   "metadata": {},
   "source": [
    "## NB with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(projected_train, y_train).predict(projected_test)\n",
    "\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d375f3d7",
   "metadata": {},
   "source": [
    "So indeed, PCA can make a difference in speed and accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
