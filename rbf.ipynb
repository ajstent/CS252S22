{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAME HERE**\n",
    "\n",
    "Spring 2023\n",
    "\n",
    "CS 251: Data Analysis and Visualization\n",
    "\n",
    "Project 7: Radial Basis Function Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: RBF Network development dataset\n",
    "\n",
    "The eventual goal is to train a neural network so that it learns to recognize which human handwritten digit is shown in an image  (i.e. the numbers 0, 1, ..., 9). Before doing this, you will use simpler data to develop and debug your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Load and preprocess data\n",
    "\n",
    "- Load in the `rbf_dev_train.csv` and `rbf_dev_test.csv` train and test sets.\n",
    "- For the train and test sets, separate the data variables (`X` and `Y`) from the class values (*class*). The test code below assumes the following names:\n",
    "    - `y_train` and `y_test` for the class values in the train and test sets, respectively.\n",
    "    - `rbf_dev_train` and `rbf_dev_test` for the train and test set data, respectively.\n",
    "- Normalize each data feature \"separately\" between 0 and 1 (based on each feature's dynamic range).\n",
    "    - Use the `min` and `max` values derived from the training set to normalize the test set. *This will ensure that identical feature values in the training and test sets get normalized to the same numeric value.*\n",
    "\n",
    "**Tip:** It might be a good idea to write a few functions below so that you don't have a lot of duplicate code when processing train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing test code\n",
    "\n",
    "The following test code is a good sanity check, but you are encouoraged to do additional testing to make sure that your preprocessing pipeline is working properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Your training set is an ndarray? {isinstance(rbf_dev_train, np.ndarray)}')\n",
    "print(f'Your training classes is an ndarray? {isinstance(y_train, np.ndarray)}')\n",
    "print(f'Your test set is an ndarray? {isinstance(rbf_dev_test, np.ndarray)}')\n",
    "print(f'Your test classes is an ndarray? {isinstance(y_test, np.ndarray)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Your training set shape is {rbf_dev_train.shape} and should be (1600, 2).')\n",
    "print(f'Your training classes shape is {y_train.shape} and should be (1600,).')\n",
    "print(f'Your test set shape is {rbf_dev_test.shape} and should be (400, 2).')\n",
    "print(f'Your test classes shape is {y_test.shape} and should be (400,).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Plot data\n",
    "\n",
    "Create a scatter plot of the training data in the cell below.\n",
    "\n",
    "- Color code each sample by its output class.\n",
    "- Make the aspect ratio (height and width) of the x and y axes in the figure equal, otherwise the plot may look distorted.\n",
    "\n",
    "If everything is working properly, you should see a jack-o-lantern whose eyes, noise, mouth, and stem are colored differently than the rest of the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Radial basis function neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbf_net import RBF_Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Network initalization\n",
    "\n",
    "You will use K-means to initialize the RBF hidden layer prototypes and sigmas.\n",
    "\n",
    "1. Copy over your `kmeans.py` from your previous project. If your K-means clustering code isn't working properly, you may use `scipy` functions in this project instead, but at a 1 point reduction. Check out `scipy.cluster.vq.kmeans`.\n",
    "\n",
    "2. Implement the method templates in `rbf.py` that initialize the hidden layer of the neural network:\n",
    "    - Finish writing the constructor\n",
    "    - `get_num_hidden_units`\n",
    "    - `get_num_output_units`\n",
    "    - `avg_cluster_dist`: Compute the average distance between each cluster center found by K-means and all the points assigned to the same cluster.\n",
    "    - `initialize`: Use K-means to set the Gaussian hidden unit centers (**prototypes**) and standard deviations (**sigmas**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `avg_cluster_dist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# N = 10 samples, M = 5 features\n",
    "test_data = np.random.normal(size=(10, 5))\n",
    "# 4 hidden units / prototypes, each has 5 features\n",
    "test_centroids = np.random.normal(size=(4, 5))\n",
    "# Each sample assigned to one of 4 hidden unit prototypes\n",
    "test_assignments = np.random.randint(low=0, high=4, size=(10,))\n",
    "kmeansObj = KMeans()\n",
    "\n",
    "test_net = RBF_Net(4, 3)\n",
    "print(f'Number of hidden units in your net is {test_net.get_num_hidden_units()} and should be 4')\n",
    "print(f'Number of output units in your net is {test_net.get_num_output_units()} and should be 3')\n",
    "test_clust_mean_dists = test_net.avg_cluster_dist(test_data, test_centroids, test_assignments, kmeansObj)\n",
    "\n",
    "print(f'Your avg within cluster distances are\\n{test_clust_mean_dists} and should be\\n[2.23811 3.94891 3.12267 3.4321]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `initialize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "test_net.initialize(test_data)\n",
    "\n",
    "print(f'Your prototypes have shape {test_net.get_prototypes().shape} and the shape should be (4, 5).')\n",
    "print(f'Your hidden unit sigmas have shape {test_net.sigmas.shape} and the shape should be (4,).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test initialization methods\n",
    "\n",
    "In the cell below, write test code for your RBF network initialization:\n",
    "- Create a new RBF network with 7 hidden units and 2 output classes.\n",
    "- Call the `initalize` method on it, passing in the training data.\n",
    "- Create a class color-coded scatterplot of the training data with an equal axis aspect ratio, like above, now with the prototypes clearly marked with a different marker and/or color.\n",
    "\n",
    "You should see fairly evenly distributed prototypes, with one in most, if not all, \"pockets\" of samples belonging to a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Do you think the prototypes enable the RBF network to learn the data well? Why or why not?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Compute hidden and output layer activations\n",
    "\n",
    "Implement the following methods so that you can train your RBF network:\n",
    "- `hidden_act`: Computes hidden layer activation values: Determines the similarity between hidden layer prototypes with the input data.\n",
    "- `output_act`: Computes output layer activation values: Multiply hidden unit activation by output unit weights.\n",
    "\n",
    "**Hidden unit activation**:\n",
    "\n",
    "The activation of hidden unit $j$ to data sample $i$ is computed according to $$H_{ij} = \\exp \\left (-\\frac{\\text{dist} \\left (\\vec{x}_i, \\vec{c}_j \\right )^2}{2\\sigma_j^2 + \\epsilon}\\right )$$ \n",
    "where $\\vec{x_i}$ is the data sample, $\\vec{c_j}$ is the prototype (center) of the hidden unit, $\\sigma_j$ is the hidden unit's standard deviation, $\\epsilon$ is a small number (e.g. 1e-8), and $dist(\\cdot, \\cdot)^2$ is the **squared** Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test hidden_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# N = 3 samples, M = 5 features\n",
    "test_data = np.random.normal(size=(3, 5))\n",
    "# 4 hidden units / prototypes, each has 5 features\n",
    "test_centroids = np.random.normal(size=(4, 5))\n",
    "# Each sample assigned to one of 4 hidden unit prototypes\n",
    "test_sigmas = np.random.uniform(size=(4,))\n",
    "test_wts = 2*np.random.uniform(size=(4+1, 3)) - 1\n",
    "\n",
    "test_net = RBF_Net(4, 3)\n",
    "test_net.prototypes = test_centroids\n",
    "test_net.sigmas = test_sigmas\n",
    "test_net.wts = test_wts\n",
    "test_h_act = test_net.hidden_act(test_data)\n",
    "print(f'Your hidden layer activation is\\n{test_h_act}\\n\\nand should be')\n",
    "print('[[0.      0.      0.00009 0.00033]\\n [0.00013 0.      0.00004 0.00014]\\n [0.      0.      0.      0.00001]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test output_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_act = test_net.output_act(test_h_act)\n",
    "print(f'Your output layer activation is\\n{test_out_act}\\n\\nand should be')\n",
    "print('[[-0.72136  0.61505 -0.20481]\\n [-0.72151  0.61487 -0.20466]\\n [-0.72144  0.61479 -0.20465]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Learn network weights using linear regression\n",
    "\n",
    "To train your RBF network, you will need to find optimal weights between hidden and output layer neurons to allows your network to accurately classify the training data (i.e. learn from the data). An efficient solution is to use linear regression to solve a least square problem: minimizing the squared difference between the *hidden layer activations* and the *true data classes*.\n",
    "\n",
    "- **CS251:** In `rbf.py`, implement `linear_regression(A, y)`. To do this, adapt your code from the linear regression project involving `scipy.linalg.lstsq()` or `numpy.linalg.lstsq()`.\n",
    "- **CS252:** In `rbf.py`, implement `linear_regression(A, y)`. To do this, adapt your code in `linear_regression` to use your QR solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test linear regression\n",
    "\n",
    "Running the following test code should generate a familar regression fit to the Iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')\n",
    "iris = df[['sepal_length', 'petal_width']].to_numpy()\n",
    "\n",
    "num_hidden_units = 1\n",
    "num_classes = 4\n",
    "net = RBF_Net(num_classes=num_classes, num_hidden_units=num_hidden_units)\n",
    "iris_x = np.reshape(iris[:, 0], [len(iris), 1])\n",
    "iris_y = np.reshape(iris[:, 1], [len(iris), 1])\n",
    "iris_c = net.linear_regression(iris_x, iris_y)\n",
    "\n",
    "line_x = np.linspace(iris_x.min(), iris_x.max())\n",
    "line_y = line_x * iris_c[0] + iris_c[1]\n",
    "plt.scatter(iris_x, iris_y)\n",
    "plt.plot(line_x, line_y)\n",
    "plt.title('Iris — Linear Regression test')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Train your RBF Network\n",
    "\n",
    "Implement the following methods then train your neural network! In the cell below, train a RBF network with 10 hidden units on the RBF dev dataset. **If everything is working, you should get >=88% accuracy on the training set and >=89% on the test set.**\n",
    "\n",
    "- `train`: Determine the optimal output layer weights that fit hidden layer activation using linear regression.\n",
    "- `predict`: Use trained network (after learning) to predict the class of data.\n",
    "- `accuracy`: Compute the accuracy by comparing the network predicted and actual class for each data sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Handwritten digit classification: MNIST data\n",
    "\n",
    "You will train a RBF network on a \"real\" image dataset of handwritten number digits:\n",
    "- 60,000 images in training set, 10,000 images in test set.\n",
    "- Each image is 28x28 pixels.\n",
    "- The images are grayscale (no RGB colors).\n",
    "- Each image (data sample) contains ONE of 10 numeric digit $0, 1, 2, \\ldots, 8, 9$.\n",
    "\n",
    "The goal is to train your network so that it can correctly predict the numeric digit in an image.\n",
    "\n",
    "More information about MNIST: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Load in and look at MNIST dataset\n",
    "\n",
    "- Use the numpy function `load` to load in the MNIST train/test data and the associated class labels.\n",
    "- Create a 5x5 grid showing the first 25 images in the dataset. It should \"look good\" (e.g. turn off tick marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Your training set shape is {x_train.shape} and should be (60000, 28, 28).')\n",
    "print(f'Your training classes shape is {y_train.shape} and should be (60000,).')\n",
    "print(f'Your test set shape is {x_test.shape} and should be (10000, 28, 28).')\n",
    "print(f'Your test classes shape is {y_test.shape} and should be (10000,).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Preprocess data\n",
    "\n",
    "- Flatten non-leading dimensions of the train and test sets. For example, the training set should go from (60000, 28, 28) to (60000, 784). **Do not hard code this!** Your code should work for any data with three dimensions.\n",
    "- Normalize so that the maximum possible value in each image is 1 (and the minimum possible is 0) by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Train and assess performance on MNIST\n",
    "\n",
    "Train a RBF network on MNIST. **Your goal is to get >=90% accuracy on both train and test sets.**\n",
    "\n",
    "**Tips:**\n",
    "- Depending on your laptop or machine you are using, training could take many hours if you use the full 60,000 sample training set. Select a subset to train on (e.g. ~1500) that takes a reasonable amount of time (e.g. minutes). You should be able to hit your accuracy goals without too much data, effort, or time.\n",
    "- Do not pare down the test set (i.e. it should remain at 10,000 samples).\n",
    "- Use the code below to visualize your hidden layer prototypes to help with debugging (assumes your network is called `mnist_net`). Your prototypes should look like images of certain digits, perhaps a little blurrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network hidden layer prototypes\n",
    "prototypes = mnist_net.get_prototypes()\n",
    "prototypes = np.reshape(prototypes, [prototypes.shape[0], 28, 28])\n",
    "\n",
    "cols = rows = 5\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        axes[i, j].imshow(prototypes[i*rows + j])\n",
    "        axes[i, j].set_xticks([])\n",
    "        axes[i, j].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Which part of the training process takes the longest?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** What accuracy did you achieve on the training set? List all parameters that you needed to set (e.g. number of training samples, number hidden units, etc)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Using the same parameters to get the training accuracy that you reported in Question 3, what test accuracy did you achieve?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "To receive credit for any extension, you must:\n",
    "- Not modify / prevent any code from the core project from working (e.g. make a copy before changing). In other words, **the notebook test code should still work!**\n",
    "- **You must describe what you did and what you found in detail**. This includes a summary of parameter values used in your simulations.\n",
    "- Include (*labeled!*) plots and/or numbers to present your results.\n",
    "- Write up your extensions below or in a separate notebook.\n",
    "\n",
    "**Rule of thumb: one deep, thorough extension is worth more than several quick, shallow extensions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Improve performance on MNIST with PCA\n",
    "\n",
    "Using all 768 features (pixels) in each image may not be very helpful for classification. For example, pixels around the border are almost always white. Transform the dataset(s) using PCA to compress the number of features before training your RBF network. Experiment with PCA to improve classification accuracy and runtime performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Visualize network predictions\n",
    "\n",
    "Make visualizations to show and interpret the MNIST network predictions. Lots of possibilities, here are a few specific ideas:\n",
    "- Make show a grid of test samples labeled with their predicted digit.\n",
    "- Analyze if the network performance favors accuracy for certain digits and not others.\n",
    "- Are errors on certain classes correlated in any way? Does it depend on their digit similarity (e.g. 1 looks like a 7, but not a 0).\n",
    "- Make and interpret a confusion plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Explore parameter space\n",
    "\n",
    "When training your RBF network on MNIST, you had to pick some parameter values to use by hand. Pick one or more parameters and systematically vary them to quantify their effect on accuracy and simulation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Initialization schemes\n",
    "\n",
    "Research, test out, and quantify the performance of different techniques to set the hidden unit prototypes and sigmas. For example, an alternative way to initialize the prototypes is to perform K-means to cluster each class *separately*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Other datasets\n",
    "\n",
    "Use your RBF network to classify other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) SVD-based linear regression\n",
    "\n",
    "Implement a SVD-based linear regression method, which is both fast and numerically accurate. In the equation $Ac = y$ The weights $c$ can be solved via the following matrix equation: $$c = A^+y$$ where $A^+$ is the pseudo inverse of the matrix of RBF hidden layer activations $A$ (*data matrix*) and the correct classes $y$.\n",
    "\n",
    "Relying on numpy to figure out the pseudoinverse would be a mini extension, computing the pseudoinverse yourself would be a larger extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Analyze the trained network\n",
    "\n",
    "Run simulations then analyze and interpret the results. Here are some ideas:\n",
    "- Visualize and analyze how the prototypes influence the classification results.\n",
    "- Visualize and analyze how the network weights influence the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) RBF networks for regression (CS252)\n",
    "\n",
    "- Analyze the regression neural network's performance in scenarios when the training set is not equal to the training set.\n",
    "- Explore and analyze how the RBF network could perform regression on a function with several inputs (e.g. $z = f(x, y)$). Test with real or simulated data.\n",
    "- Explore and analyze how the RBF network could perform regression on a vector valued function with several outputs (e.g. $(y, z) = f(x)$). Test with real or simulated data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
