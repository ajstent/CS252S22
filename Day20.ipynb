{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0e7ca52",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "\n",
    "# Timings of Quizzes and Homeworks\n",
    "\n",
    "# The One Goal For Today\n",
    "\n",
    "Understand how normalization first helps or hinders PCA and linear regression models.\n",
    "\n",
    "## Review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy.linalg as sp_la"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6243b190",
   "metadata": {},
   "source": [
    "### Load and Look at Your Data\n",
    "\n",
    "Today I will keep working with the set of Craigslist listings for used cars. For the homework, you will work with your own data set!\n",
    "\n",
    "This code below you can use as a **tool**.\n",
    "* Change the columns to the columns for your data\n",
    "* Change the tuple in \"usecols\" to the tuples for your data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3775ce",
   "metadata": {},
   "source": [
    "First we make data converters for non-numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will be our columns\n",
    "columns = [\"price\", \"year\", \"manufacturer\", \"model\", \"condition\", \"fuel\", \"odometer\", \"title_status\", \"transmission\"]\n",
    "# this will contain our converters\n",
    "colValues = {}\n",
    "\n",
    "# first we load our data as strings so we can define the converters\n",
    "data = np.array(np.genfromtxt('data/vehicles.csv', delimiter=',', usecols=(1,2,3,4,5,7,8,9,11), skip_header=1, dtype=str, encoding='utf-8'))  \n",
    "\n",
    "# make a list of the unique values in each column of our data\n",
    "for colIndex in range(data.shape[1]):\n",
    "    colValues[colIndex] = np.unique(data[:, colIndex]).tolist()\n",
    "    print(colIndex, colValues[colIndex])\n",
    "\n",
    "# map values to their indices in the list of unique values\n",
    "def converter(x, colIndex):\n",
    "    return colValues[colIndex].index(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8571c1f",
   "metadata": {},
   "source": [
    "Then we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca359103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(np.genfromtxt('data/vehicles.csv', delimiter=',', usecols=(1,2,3,4,5,7,8,9,11), converters={3: lambda x: converter(x, 2), 4: lambda x: converter(x, 3), 5: lambda x: converter(x, 4), 7: lambda x: converter(x,5), 9: lambda x: converter(x, 7), 11: lambda x: converter(x, 8)}, skip_header=1, dtype=int, encoding='utf-8'))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68a5a5ca",
   "metadata": {},
   "source": [
    "Then we get summary statistics and a pairplot of the independent variables vs the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    return pd.DataFrame([data.min(axis=0), data.max(axis=0), data.mean(axis=0), data.std(axis=0)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ceb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=columns)\n",
    "seaborn.pairplot(df, y_vars = columns[0], x_vars = columns[1:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0695d83",
   "metadata": {},
   "source": [
    "### Normalize Your Data\n",
    "\n",
    "Here we implement max-min global, max-min local, z-score and center, all in one function. If you see a bug, tell us!\n",
    "\n",
    "This code you can use as a **tool**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa19fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, method='center'):\n",
    "    if method == 'center':\n",
    "        return data - np.mean(data, axis=0)\n",
    "    elif method == 'max-min-global':\n",
    "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    elif method == 'max-min-local':\n",
    "        return (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n",
    "    elif method == 'zscore':\n",
    "        return (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    else:\n",
    "        raise Exception(\"I can't do \" + method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5352ca4",
   "metadata": {},
   "source": [
    "Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = normalize(data, method='zscore')\n",
    "df = pd.DataFrame(normalized_data, columns=columns)\n",
    "seaborn.pairplot(df, y_vars = columns[0], x_vars = columns[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db0d2a99",
   "metadata": {},
   "source": [
    "Once you have figured out which type of normalization to do, set data to the normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517578ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalized_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad0b841e",
   "metadata": {},
   "source": [
    "# Impact of Normalization on Regression\n",
    "\n",
    "The code below will fit a linear or polynomial regression using the independent and dependent variables of your choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccdae3d3",
   "metadata": {},
   "source": [
    "Let's split our data into **train** and **test**. \n",
    "\n",
    "This code you can use as a **tool**.\n",
    "* I sort by the car data by time first. \n",
    "* You should figure out if you need to sort your data (or shuffle your data) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to shuffle your data\n",
    "np.random.shuffle(data)\n",
    "print(data[0:5])\n",
    "\n",
    "# if you need to sort your data; I'm sorting by column 1, time\n",
    "data = data[data[:, 1].argsort()]\n",
    "print(data[0:5])\n",
    "\n",
    "(train, test) = np.split(data, [int(len(data) / 10 * 8)])\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "064c2fbf",
   "metadata": {},
   "source": [
    "This comes directly from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22199c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x an array of multiple independent variables\n",
    "# poly -> polys, an array of multiple polynomial degrees for each column in x in order\n",
    "def makePoly(x, polys):\n",
    "    # make an empty array of size A\n",
    "    A = np.zeros([x.shape[0], np.sum(polys)+1])\n",
    "    # left most column of 1s for the intercept\n",
    "    A[:, 0] = np.squeeze(x[:, 0]**0)\n",
    "    k = 1\n",
    "    for (j, poly) in enumerate(polys):\n",
    "        for i in range(1, poly+1):\n",
    "            A[:, k] = np.squeeze(x[:, j]**i)\n",
    "            k += 1\n",
    "    return A\n",
    "\n",
    "def fit_lr(data, independent, dependent, polys):\n",
    "    # These are our independent variables\n",
    "    x = data[np.ix_(np.arange(data.shape[0]), independent)] \n",
    "    # This is the dependent variable \n",
    "    y = data[:, dependent]\n",
    "    A = makePoly(x, polys)\n",
    "    c, _, _, _ = sp_la.lstsq(A, y)\n",
    "    return c\n",
    "\n",
    "def predict_lr(data, independent, polys, c):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[np.ix_(np.arange(data.shape[0]), independent)]\n",
    "    A = makePoly(x, polys)\n",
    "    return np.dot(A, c)\n",
    "\n",
    "def msse(y, yhat):\n",
    "    r = ((y - yhat)**2).mean()\n",
    "    return r\n",
    "\n",
    "def rsquared(y, yhat):\n",
    "    return 1 - (((y - yhat)**2).sum() / ((y - y.mean())**2).sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65f8ca28",
   "metadata": {},
   "source": [
    "This next cell calculates a multiple linear regression on the data using all the independent variables.\n",
    "\n",
    "**If your dependent variable is not at 0, modify this cell before running!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = list(range(1, train.shape[1]))\n",
    "polys = [1 for x in independent]\n",
    "c = fit_lr(train, independent, 0, polys)\n",
    "yhat_train = predict_lr(train, independent, polys, c)\n",
    "yhat_test = predict_lr(test, independent, polys, c)\n",
    "print(msse(train[:, 0], yhat_train), rsquared(test[:, 0], yhat_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47eb5d11",
   "metadata": {},
   "source": [
    "And this next cell fits a polynomial regression using all the independent variables, with only the one at index 1 raised to the power 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = list(range(1, train.shape[1]))\n",
    "polys = [1 for x in independent]\n",
    "polys[0] = 2\n",
    "c = fit_lr(train, independent, 0, polys)\n",
    "yhat_train = predict_lr(train, independent, polys, c)\n",
    "yhat_test = predict_lr(test, independent, polys, c)\n",
    "print(msse(train[:, 0], yhat_train), rsquared(test[:, 0], yhat_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba2d257b",
   "metadata": {},
   "source": [
    "Try regression:\n",
    "* without any data normalization\n",
    "* with each method of data normalization\n",
    "\n",
    "What works best?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06d2cb29",
   "metadata": {},
   "source": [
    "# Impact of Normalization on PCA\n",
    "\n",
    "The code below comes from this week. I just put it in functions. This code you can use as a **tool**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pca(data):\n",
    "    # center\n",
    "    centered_data = data - np.mean(data, axis=0)\n",
    "    # covariance matrix\n",
    "    covariance_matrix = (centered_data.T @ centered_data) / (data.shape[0] - 1)\n",
    "    # plot covariance matrix\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    seaborn.heatmap(pd.DataFrame(covariance_matrix), annot=False, cmap='PuOr')\n",
    "    plt.show()\n",
    "    # eigenvalues and eigenvectors, sorted\n",
    "    (evals, evectors) = np.linalg.eig(covariance_matrix)\n",
    "    order = np.argsort(evals)[::-1]\n",
    "    eigenvals_sorted = evals[order]\n",
    "    eigenvecs_sorted = evectors[:, order]\n",
    "    print(eigenvals_sorted.shape, eigenvecs_sorted.shape)\n",
    "    return np.mean(data, axis=0), eigenvals_sorted, eigenvecs_sorted\n",
    "\n",
    "def variances(eigenvals_sorted, eigenvecs_sorted):\n",
    "    # calculate proportional variances and cumulative sum\n",
    "    sum = np.sum(eigenvals_sorted)\n",
    "    proportional_variances = np.array([eigenvalue / sum for eigenvalue in eigenvals_sorted])\n",
    "    cumulative_sum = np.cumsum(proportional_variances)\n",
    "    # scree plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(len(proportional_variances)), proportional_variances, alpha=0.5, align='center',\n",
    "            label='Proportional variance')\n",
    "    plt.ylabel('Proportional variance ratio')\n",
    "    plt.xlabel('Ranked Principal Components')\n",
    "    plt.title(\"Scree Graph\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    # elbow plot\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(cumulative_sum)\n",
    "    ax1.set_ylim([0,1.0])\n",
    "    ax1.set_xlabel('Number of Principal Components')\n",
    "    ax1.set_ylabel('Cumulative explained variance')\n",
    "    ax1.set_title('Elbow Plot')\n",
    "    plt.show()\n",
    "\n",
    "def project_pca(data, mean, eigenvecs_sorted, to_keep):\n",
    "    centered_data = data - mean\n",
    "    return centered_data@eigenvecs_sorted[:, :to_keep]\n",
    "\n",
    "def reconstruct_pca(projected_data):\n",
    "    return projected_data@v.T + np.mean(data, axis=0)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc165551",
   "metadata": {},
   "source": [
    "Let's try it on our training data. \n",
    "\n",
    "**If you intend to fit a model (for example, linear regression) after transforming your data using PCA, you should fit the PCA using your training data only. Then, transform your training and test data using the eigenvalues and eigenvectors from your training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f18457",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = list(range(1, train.shape[1]))\n",
    "train_x = train[np.ix_(np.arange(train.shape[0]), independent)] \n",
    "# split off the dependent variable, which we don't want to include in the PCA model\n",
    "train_y = train[:, 0]\n",
    "test_x = test[np.ix_(np.arange(test.shape[0]), independent)] \n",
    "# split off the dependent variable, which we don't want to include in the PCA model\n",
    "test_y = test[:, 0]\n",
    "\n",
    "mean, eigenvals_sorted, eigenvecs_sorted = fit_pca(train_x)\n",
    "variances(eigenvals_sorted, eigenvecs_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = 7\n",
    "projected_train = project_pca(train_x, mean, eigenvecs_sorted, to_keep)\n",
    "# stick the dependent variable back on!\n",
    "projected_train = np.hstack((np.array([train_y]).T, projected_train))\n",
    "print(train.shape, projected_train.shape)\n",
    "projected_test = project_pca(test_x, mean, eigenvecs_sorted, to_keep)\n",
    "# stick the dependent variable back on!\n",
    "projected_test = np.hstack((np.array([test_y]).T, projected_test))\n",
    "print(test.shape, projected_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a48d068a",
   "metadata": {},
   "source": [
    "Try PCA:\n",
    "* without any data normalization\n",
    "* with each method of data normalization\n",
    "\n",
    "Which works best?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f30ff7ef",
   "metadata": {},
   "source": [
    "# Compare Regression on Raw vs PCA Transformed Data\n",
    "\n",
    "Now for your data set, compare the performance of regression on the raw data vs the (normalized and) PCA transformed data.\n",
    "\n",
    "There's a lot to consider here, so I'd suggest keeping a log in the form of the table below.\n",
    "\n",
    "| Normalization | PCA? | Independent variables | Polynomials | MSSE on Train | $R^2$ on Test | \n",
    "| ------------- | ---- | --------------------- | ----------- | ------------- | ------------- |\n",
    "|     none      |   no |            all        |   all 1     |               |               |\n",
    "| max-min-local |   keep 7 |        all        |   first principal component squared, rest 1    |               |               |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3c676dd",
   "metadata": {},
   "source": [
    "This next cell calculates a multiple linear regression on the data using all the independent variables.\n",
    "\n",
    "**If your dependent variable is not at 0, modify this cell before running!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = list(range(1, projected_train.shape[1]))\n",
    "polys = [1 for x in independent]\n",
    "c = fit_lr(projected_train, independent, 0, polys)\n",
    "yhat_train = predict_lr(projected_train, independent, polys, c)\n",
    "yhat_test = predict_lr(projected_test, independent, polys, c)\n",
    "print(msse(train[:, 0], yhat_train), rsquared(test[:, 0], yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de17cd7",
   "metadata": {},
   "source": [
    "And this next cell fits a polynomial regression using all the independent variables, with only the one at index 1 raised to the power 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3238e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = list(range(1, projected_train.shape[1]))\n",
    "polys = [1 for x in independent]\n",
    "polys[0] = 2\n",
    "c = fit_lr(projected_train, independent, 0, polys)\n",
    "yhat_train = predict_lr(projected_train, independent, polys, c)\n",
    "yhat_test = predict_lr(projected_test, independent, polys, c)\n",
    "print(msse(train[:, 0], yhat_train), rsquared(test[:, 0], yhat_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
