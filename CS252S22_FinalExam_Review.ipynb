{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finalExamUtilities as fEU\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy.linalg as sp_la\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16737ff",
   "metadata": {},
   "source": [
    "# Overall Review <a class=\"anchor\" id=\"review\"></a>\n",
    "\n",
    "\n",
    "Today we are going to load a dataset and use it to review each type of data analysis method we have looked at this semester.\n",
    "\n",
    "Here's the scenario: You have been hired for the summer by a local realty company that manages apartment complexes. When someone applies to rent an apartment, the company collects information about the applicant, including information about debt, income and credit rating. The company has a shortage of staff to process applications, and is also dealing with a fair housing-related lawsuit. The company would like you to develop an automated solution for determining whether applicants are rent-worthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412055f4",
   "metadata": {},
   "source": [
    "# Prepare The Data <a class=\"anchor\" id=\"prepData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba73819",
   "metadata": {},
   "source": [
    "## 1. Load and look at your data <a class=\"anchor\" id=\"loadData\"></a>\n",
    "\n",
    "* Where does the data come from? *This data set comes from https://www.kaggle.com/datasets/samuelcortinhas/credit-card-approval-clean-data which in turn comes from https://archive.ics.uci.edu/ml/datasets/Credit+Approval. It was originally contributed in Robert Quinlan in the late 1980s/early 1990s.*\n",
    "  * What are the variables?\n",
    "  * What are the types of the variables?\n",
    "* Are there any ethical concerns with using this data? *This data set is about credit scoring, so (unless it's artificial, in which case we have different concerns!) it includes information about individuals.\n",
    "  * We check whether any personally identifying information is in the data and no, there is none (no names, addresses, social security numbers, etc).\n",
    "  * Even if no PII is in the data, there are sensitive features in the data such as age, gender and ethnicity. Models that use these features should be subject to extra scrutiny to make sure they are not biased in favor of one group of people over another. In our experiments today, we will *exclude these features*.\n",
    "  * The data includes a label for credit-worthiness. Historically, human-made decisions about credit-worthiness (and rent-worthiness) have been notably subject to bias. So we should tell the realty company not to deploy any model we create as the sole decision maker.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6593f0",
   "metadata": {},
   "source": [
    "Referring to the cell below, which contains a report of the data with sensitive variables 'age', 'gender', 'ethnicity' and 'citizen' filtered out, please answer:\n",
    "\n",
    "* How many data points are there?\n",
    "* How many variables are there?\n",
    "* What is the type of each variable?\n",
    "  * syntactic types:\n",
    "  * semantic types:\n",
    "* Are the variables independent of each other? How do you make that assessment?\n",
    "* Is there a value for each variable for each data point? \n",
    "* Do the values make sense? Are there outliers or other insanities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedData = fEU.prepData(dataName=\"cc\", type=\"clustering\", fractionToKeep=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f2800",
   "metadata": {},
   "source": [
    "* What would be a reasonable choice of dependent variable in this dataset, and why, for:\n",
    "  * regression?\n",
    "  * classification?\n",
    "* What shall we split our data into, and why?\n",
    "* What do we need to watch out for as we split our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8149c",
   "metadata": {},
   "source": [
    "## 2. Consider Transforming/Normalizing the Data <a class=\"anchor\" id=\"normalizeData\"></a>\n",
    "\n",
    "* Do we need to transform this data? Why or why not?\n",
    "* If we do need to transform it, what will we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8ae19",
   "metadata": {},
   "source": [
    "## 3. Consider Dimensionality Reduction <a class=\"anchor\" id=\"pcaData\"></a>\n",
    "\n",
    "* In what circumstances do we want to use dimensionality reduction?\n",
    "* What method do we use for dimensionality reduction?\n",
    "* What are the steps in this method?\n",
    "* One way to choose how many dimensions to keep is by looking at an elbow plot. Looking at the one below, how many dimensions should we keep for this data set in order to retain 80% of the cumulative explained variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = fEU.PCA(centered=True, plot=True)\n",
    "pca.fit(transformedData)\n",
    "#projected = pca.project(transformedData, ??)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e59f1d",
   "metadata": {},
   "source": [
    "[Go back to the top](#review)\n",
    "\n",
    "\n",
    "# Model <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeafb4d",
   "metadata": {},
   "source": [
    "## 4. Regression <a class=\"anchor\" id=\"regression\"></a>\n",
    "\n",
    "* To fit a regression, the type of the dependent variable should be what?\n",
    "* Name and define the loss function for regression.\n",
    "* The normal equation is one method for fitting a linear regression. What is the normal equation? When can we *not* use it?\n",
    "* If I have a lot of variables in my data, how can I effectively decide which to include in my regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedTrain, transformedDev, transformedTest, trainY, devY, testY = fEU.prepData(dataName=\"cc\", type=\"regression\", fractionToKeep=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Linear regression on the transformed data\n",
    "\n",
    "lr = LinearRegression().fit(transformedTrain, trainY)\n",
    "print(lr.score(transformedDev, devY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Polynomial regresson the transformed data, degree 2\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False, interaction_only = True)\n",
    "polynomial2Train = pf.fit_transform(transformedTrain)\n",
    "lr = LinearRegression().fit(polynomial2Train, trainY)\n",
    "polynomial2Dev = pf.fit_transform(transformedDev)\n",
    "print(lr.score(polynomial2Dev, devY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c697c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Polynomial regresson the transformed data, degree 3\n",
    "pf = PolynomialFeatures(degree = 3, include_bias = False, interaction_only = True)\n",
    "polynomial2Train = pf.fit_transform(transformedTrain)\n",
    "lr = LinearRegression().fit(polynomial2Train, trainY)\n",
    "polynomial2Dev = pf.fit_transform(transformedDev)\n",
    "print(lr.score(polynomial2Dev, devY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5923b90",
   "metadata": {},
   "source": [
    "[Go back to the top](#review)\n",
    "\n",
    "## 5. Clustering <a class=\"anchor\" id=\"clustering\"></a>\n",
    "\n",
    "* In what circumstances would we want to cluster our data?\n",
    "* Clustering requires a distance metric. Name and define a distance metric *other than Euclidean distance*.\n",
    "* For k-means clustering, we minimize *inertia*. Define inertia.\n",
    "* k-means clustering is sensitive to the structure of the input data. In what way? How can we fix this type of issue with data structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03afa8f",
   "metadata": {},
   "source": [
    "[Go back to the top](#review)\n",
    "\n",
    "# Classification <a class=\"anchor\" id=\"classification\"></a>\n",
    "\n",
    "* To train a classifier, the type of the dependent variable should be what?\n",
    "* We will use \"credit-worthy\" as a proxy for \"rent-worthy\". How many values does this variable have?\n",
    "* How do we know how well a classification model works?\n",
    "\n",
    "## 6. K-nearest neighbors <a class=\"anchor\" id=\"knn\"></a>\n",
    "\n",
    "* How does the *fit* function work for k-nearest neighbors?\n",
    "* How does the *predict* function work?\n",
    "* One way to choose a value of $k$ is by looking at an elbow plot. Looking at the elbow plot below, what value of k would you choose for this data and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c86aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedTrain, transformedDev, transformedTest, trainY, devY, testY = fEU.prepData(dataName=\"cc\", type=\"classification\", fractionToKeep=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit a kNN to the transformed train data, choose k using dev data; this is hyperparameter tuning\n",
    "\n",
    "fEU.fitExploreKNN(transformedTrain, trainY, transformedDev, devY, 2, 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02208570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit a kNN to the transformed train data, best k, test using test data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=?).fit(transformedTrain, trainY)\n",
    "print(knn.score(transformedTest, testY))\n",
    "print(confusion_matrix(testY, knn.predict(transformedTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387853d1",
   "metadata": {},
   "source": [
    "## 7.  Naive Bayes <a class=\"anchor\" id=\"nb\"></a>\n",
    "\n",
    "* State Bayes rule.\n",
    "* In Bayes rule, which parts are the posterior, prior, likelihood and evidence?\n",
    "* Why do we call a Naive Bayes model \"naive\"? What does this allow us to do?\n",
    "* A simple Naive Bayes model is based on relative frequencies of values of the variables in the training data. \n",
    "  * How can we account for values of variables we may not see for a particular class at train time?\n",
    "  * The estimated probabilities output via this method, for any non-trivial number of variable values, will be very small. How can we handle this?\n",
    "  * If a variable is quantitative (continuous or discrete) we can fit a Naive Bayes model using a probability density function for the variable. Name and define a probability distribution commonly used in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedTrain, transformedDev, transformedTest, trainY, devY, testY = fEU.prepData(dataName=\"cc\", type=\"classification\", fractionToKeep=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fit a naive Bayes model to the transformed train data, test using test data\n",
    "\n",
    "gnb = GaussianNB().fit(transformedTrain, trainY)\n",
    "print(gnb.score(transformedTest, testY))\n",
    "print(confusion_matrix(testY, gnb.predict(transformedTest)))\n",
    "fEU.aucRoc(gnb.predict(transformedTest), testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3671227",
   "metadata": {},
   "source": [
    "[Go back to the top](#review)\n",
    "\n",
    "## Evaluation and Visualization <a class=\"anchor\" id=\"classificationEvaluation\"></a>\n",
    "\n",
    "* In addition to accuracy, we often create confusion matrices for a classifier.\n",
    "  * Draw a confusion matrix and label the cells corresponding to true positives, true negatives, false positives and false negatives\n",
    "  * Looking at the confusion matrix above, what can we say about the classes in this model?\n",
    "  * Define true positive rate and false positive rate.\n",
    "  * What is a ROC curve? How is it related to AUC?\n",
    "  * For a multiclass classifier, what is a variant on the vanilla confusion matrix that we can use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a4c3e",
   "metadata": {},
   "source": [
    "[Go back to the top](#review)\n",
    "\n",
    "# 8. RBF Networks <a class=\"anchor\" id=\"rbfNetworks\"></a>\n",
    "\n",
    "* What is a radial basis function?\n",
    "* What is the structure of a RBF network?\n",
    "* In this course, what type of activation function did we define for the hidden nodes?\n",
    "* What are the steps to training a RBF network?\n",
    "* For what types of modeling can we use a RBF network?\n",
    "\n",
    "Let's think about training a RBF network to determine whether an applicant is \"rent-worthy\".\n",
    "* How many nodes will be in the input layer?\n",
    "* How many nodes will be in the output layer?\n",
    "* Thinking about the k-means clustering we trained on this data earlier, how many nodes would you put in the hidden layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68e75f",
   "metadata": {},
   "source": [
    "## A Worked Example for Regression <a class=\"anchor\" id=\"rbfRegression\"></a>\n",
    "\n",
    "Which is more accurate, linear regression (see earlier) or regression via RBF network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedTrain, transformedDev, transformedTest, trainY, devY, testY = fEU.prepData(dataName=\"cc\", type=\"regression\", fractionToKeep=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get the number of prototypes; this is hyperparameter tuning\n",
    "\n",
    "rbf = fEU.RBFNetwork(type=\"regression\")\n",
    "rbf.explorePrototypes(transformedTrain, 2, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537af869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rbf.fit(transformedTrain, trainY, 15)\n",
    "yhat = rbf.predict(transformedDev)\n",
    "rbf.score(devY, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791d8a3",
   "metadata": {},
   "source": [
    "## A Worked Example for Classification <a class=\"anchor\" id=\"rbfClassification\"></a>\n",
    "\n",
    "Which is most accurate, kNN classification, Naive Bayes classification, or classification via RBF network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0968e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedTrain, transformedDev, transformedTest, trainY, devY, testY = fEU.prepData(dataName=\"cc\", type=\"classification\", fractionToKeep=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99921086",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get the number of prototypes; this is hyperparameter tuning\n",
    "\n",
    "rbf = fEU.RBFNetwork(type=\"classification\")\n",
    "rbf.explorePrototypes(transformedTrain, 2, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rbf.fit(transformedTrain, trainY, 15)\n",
    "yhat = rbf.predict(transformedDev)\n",
    "rbf.score(devY, yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
