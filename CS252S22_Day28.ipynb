{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29860ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47fc9e",
   "metadata": {},
   "source": [
    "*Last Monday I said Naive Bayes is the first data analysis method we have that is good for what type of data? Quantitative or Qualitative?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bd31f",
   "metadata": {},
   "source": [
    "# Naive Bayes for Text\n",
    "\n",
    "Text data, *without preprocessing*, is qualitative data. Let's use Naive Bayes to classify some text data! \n",
    "\n",
    "I'm going to be using the SMS dataset from [here](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "## I. Load and Look at our data\n",
    "\n",
    "Let's load and __look at our data__. Is our independent variable at the *start* or the *end*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(np.genfromtxt('data/SMSSpamCollection', delimiter='\\t', encoding='utf-8', dtype=str))  \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10895987",
   "metadata": {},
   "source": [
    "How many labels do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644772da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(data[:, 0], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4e1ee",
   "metadata": {},
   "source": [
    "## II. Split the data\n",
    "\n",
    "Let's split it into train, dev, test and make sure we have some of each label in each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ebca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = np.split(data, [int(.8 * len(data)), int(.9 * len(data))])\n",
    "print(train.shape, dev.shape, test.shape)\n",
    "print(np.unique(train[:, 0], return_counts=True))\n",
    "print(np.unique(dev[:, 0], return_counts=True))\n",
    "print(np.unique(test[:, 0], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461abc1",
   "metadata": {},
   "source": [
    "So far, so good!\n",
    "\n",
    "## III. Preprocess the data\n",
    "\n",
    "*But*, how do I deal with the SMS texts themselves? Well, a SMS is composed of word-type things (let's call them \"tokens\") and if I *completely ignore* the sequence information then I could say each SMS is composed of a bag of tokens. \n",
    "\n",
    "NOTE that to do this hurts me as a computational linguist. Of *course* word order matters! In particular, in this context it means that the token occurrences are not *independent* of each other. But we are going to pretend they are, thus lacerating the sensibilities of both linguists and statisticians in search of a computationally efficient approximation.\n",
    "\n",
    "__Our independent variables will be what, now?__\n",
    "\n",
    "### Let's define a function to get the bag of tokens from the text of a SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec04449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will split the text on any character(s) that are not letters or numbers,\n",
    "# and then keep anything that is not whitespace\n",
    "def tokenize(text):\n",
    "    return [token.strip() for token in re.split(r'([^A-Za-z0-9]+)', text) if not re.match(r'^\\s*$', token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9259a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it on one SMS\n",
    "tokenize(train[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd6875",
   "metadata": {},
   "source": [
    "### Let's get the unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "for i in range(len(train)):\n",
    "    tokens = tokens.union(tokenize(train[i][1]))\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8de881",
   "metadata": {},
   "source": [
    "That's entirely too many tokens! Let's keep just from the $a$ to the $b$ most frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 75\n",
    "b = 2000\n",
    "tokens = []\n",
    "for i in range(len(train)):\n",
    "    tokens.extend(tokenize(train[i][1]))\n",
    "uniqueTokens, tokenCounts = np.unique(tokens, return_counts=True)\n",
    "topUniqueTokens = uniqueTokens[np.argsort(tokenCounts)[::-1]][a:b]\n",
    "print(len(topUniqueTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8c8b2",
   "metadata": {},
   "source": [
    "### Let's collect token counts across all the 'ham' SMSs, and separately across all the 'spam' SMSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebaba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessCategory(subsetOfData, tokenVocab):\n",
    "    tokens = []\n",
    "    res = dict.fromkeys(tokenVocab, 0)\n",
    "    for i in range(len(subsetOfData)):\n",
    "        tokens.extend(tokenize(subsetOfData[i][1]))\n",
    "    uniqueTokens, tokenCounts = np.unique(tokens, return_counts=True)\n",
    "    for token, count in zip(uniqueTokens, tokenCounts):\n",
    "        if token in res:\n",
    "            res[token] += count\n",
    "    return res\n",
    "\n",
    "tokenCounts = {}\n",
    "tokenCounts['ham'] = preprocessCategory(train[np.where(train[:, 0] == 'ham')], topUniqueTokens)\n",
    "tokenCounts['spam'] = preprocessCategory(train[np.where(train[:, 0] == 'spam')], topUniqueTokens)\n",
    "# We keep this around for indexing into the likelihoods\n",
    "sortedTokens = sorted(topUniqueTokens)\n",
    "print(len(sortedTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecca3b6",
   "metadata": {},
   "source": [
    "Pay attention to the sleight of hand here:\n",
    "* Our labels are 'ham' and 'spam'.\n",
    "* Our features are individual token frequencies calculated across all of 'ham' and all of 'spam'. We *assume independence in the features*. That's the naive in Naive Bayes.\n",
    "\n",
    "## Fit\n",
    "\n",
    "So now let's fit a Naive Bayes model for spam detection\n",
    "\n",
    "To fit, we need to calculate:\n",
    "* priors - $P(ham)$ and $P(spam)$\n",
    "* likelihoods - for any token $x$, $P(x|ham)$ and $P(x|spam)$\n",
    "\n",
    "### Priors\n",
    "\n",
    "Calculating priors will be easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62578037",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {'ham': len(train[np.where(train[:, 0] == 'ham')]) / len(train), 'spam': len(train[np.where(train[:, 0] == 'spam')]) / len(train)}\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a8553",
   "metadata": {},
   "source": [
    "### Likelihoods\n",
    "\n",
    "Calculating likelihoods will be tricky, because:.\n",
    "* Sometimes the likelihoods will be 0, as a token will occur *no* times in one of 'ham' or 'spam'.\n",
    "* A lot of the likelihoods will be veerrrry small, as most of the tokens occur only once.\n",
    "\n",
    "To deal with these, we:\n",
    "* 0s - use *Laplace smoothing*, as we discussed last session.\n",
    "* veerrrry small - move from regular count space to log space (see plot).\n",
    "  * in 'regular count space' $P(I, like, candy) | ham) = P(I|ham)*P(like|ham)*P(candy|ham)$.\n",
    "  * in 'log space' $P(I, like, candy) | ham) = log(P(I|ham)) + log(P(like|ham)) + log(P(candy|ham))$, because the logarithm of a product is the sum of the logarithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array([[i, 1/i, np.log(1/i)] for i in range(1, 1000)])\n",
    "plt.plot(res[:, 0], res[:, 1])\n",
    "plt.plot(res[:, 0], res[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLikelihoods(data):\n",
    "    likelihoods = {}\n",
    "    cats = np.unique(train[:, 0])\n",
    "    for cat in cats:\n",
    "        likelihoods[cat] = {}\n",
    "        for token in sortedTokens:\n",
    "            likelihoods[cat][token] = np.log((tokenCounts[cat][token] + 1) / \n",
    "                                             (len(np.where([data[:, 0] == cat])) + len(sortedTokens)))\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = calculateLikelihoods(train)\n",
    "print(len(likelihoods))\n",
    "print(len(likelihoods['ham']))\n",
    "print(len(likelihoods['spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2327924",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Let's use the Naive Bayes model we fit to predict the class for each item in our test data.\n",
    "\n",
    "We will have to tokenize each SMS, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf24e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pTextGivenCategory(text, cat):\n",
    "    tokens = tokenize(text)\n",
    "    sum = 0\n",
    "    for token in tokens:\n",
    "        # if the token is not in our vocab from train, it just gets dropped\n",
    "        try:\n",
    "            likelihood = likelihoods[cat][token]\n",
    "        except:\n",
    "            likelihood = 0\n",
    "        # we add instead of multiply, because we are in log space\n",
    "        sum += likelihood\n",
    "    return sum\n",
    "        \n",
    "def predict(data):\n",
    "    labels = []\n",
    "    cats = np.unique(data[:, 0])\n",
    "    for i in range(len(data)):    \n",
    "        res = []\n",
    "        for cat in cats:\n",
    "            res.append(np.log(priors[cat]) + pTextGivenCategory(dev[i][1], cat))\n",
    "        labels.append((cats[np.argmax(res)], np.exp(res[np.argmax(res)])))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19530f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = predict(dev)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e79aa",
   "metadata": {},
   "source": [
    "## Score\n",
    "\n",
    "Let's get accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These come directly from day 24\n",
    "\n",
    "def accuracy(y, yhat):\n",
    "    assert len(y) == len(yhat)\n",
    "    diffs = y == yhat\n",
    "    vals, counts = np.unique(diffs, return_counts=True)\n",
    "    return counts[np.where(vals == True)] / (np.sum(counts))\n",
    "    \n",
    "def confusionMatrix(y, yhat):\n",
    "    \"Thanks to https://stackoverflow.com/questions/2148543/how-to-write-a-confusion-matrix-in-python\"\n",
    "    allLabels = sorted(list(np.union1d(y, yhat)))\n",
    "    print(allLabels)\n",
    "    assert len(y) == len(yhat)\n",
    "    result = np.zeros((len(allLabels), len(allLabels)))\n",
    "    for i in range(len(y)):\n",
    "        result[allLabels.index(y[i])][allLabels.index(yhat[i])] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy([x[0] for x in labels], dev[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93261504",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix([x[0] for x in labels], dev[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c82ce",
   "metadata": {},
   "source": [
    "Note that accuracy isn't super helpful here, since there are so many 'ham' emails. \n",
    "\n",
    "Question: *What would the accuracy be if the model just labeled __everything__ as 'ham'?*\n",
    "\n",
    "## TPR, FPR, Precision, Recall, F, ROC, AUC\n",
    "\n",
    "Let's make a different version of the confusion matrix focusing on just the 'spam' class, which is the class we really want to do well on:\n",
    "\n",
    "| | Predict not in 'spam' | Predict in 'spam' | Rates |\n",
    "| -- | --- | --- | -- |\n",
    "| Actual not in 'spam' | TN | FP | FPR = FP/(FP+TN) |\n",
    "| Actual in 'spam' | FN | TP | TPR = TP/(TP+FN) |\n",
    "\n",
    "With a table like this, we can also calculate:\n",
    "* Precision (how many of those we guessed were 'spam' were actually 'spam'?): TP / (TP + FP)\n",
    "* Recall (how many actual 'spam' did we guess were 'spam'?): TP / (TP + FN)\n",
    "\n",
    "Then, to get an assessment of recall and precision together, we can calculate F1: (2\\*Precision\\*Recall)/(Precision+Recall)\n",
    "\n",
    "We can also plot the ROC curve and calculate AUC.\n",
    "* ROC - receiver operating characteristic curve, constructed by plotting the TPR against the FPR\n",
    "* AUC - area under the ROC curve\n",
    "\n",
    "Here is a good introduction to these: https://www.displayr.com/what-is-a-roc-curve-how-to-interpret-it/\n",
    "\n",
    "We will plot the ROC curve using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# This code comes from https://thecleverprogrammer.com/2021/04/07/auc-and-roc-curve-using-python/\n",
    "\n",
    "# Have to convert the labels to ints for the sklearn implementation\n",
    "labelmap = ['ham', 'spam']\n",
    "auc = metrics.roc_auc_score([labelmap.index(x[0]) for x in labels], [labelmap.index(x) for x in dev[:, 0]])\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve([labelmap.index(x[0]) for x in labels], [labelmap.index(x) for x in dev[:, 0]])\n",
    "\n",
    "plt.figure(figsize=(10, 8), dpi=100)\n",
    "plt.axis('scaled')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.title(\"AUC & ROC Curve\")\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'g')\n",
    "plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgreen', alpha=0.7)\n",
    "plt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=12, weight='bold', color='blue')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f72cb",
   "metadata": {},
   "source": [
    "## Are we happy?\n",
    "\n",
    "We could potentially do better:\n",
    "* We could add information from *outside the text*. Modern spam filters use features like whether the sender's email address is the same as the reply-to email address, whether the IP address the email comes from matches that of the domain of the sender's email address, whether this same email is being sent to a lot of people at the same time, whether this sender has ever emailed this recipient before (and how often), and all kinds of behavioral features.\n",
    "* We have a *class imbalance*: there are a lot more 'ham' emails than there are 'spam' emails. We can deal with this by *changing the decision threshold*, *downsampling* the 'ham' emails, *upsampling* (repeating) the 'spam' emails, or [other techniques](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/?msclkid=33d6b961b9df11ec98e519046a973ddf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4574cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_texts = np.array([['ham', 'Thank you!'], ['spam', 'hey how are things'], ['ham', 'How is second puppy training going?'], ['ham', 'Your Clear Enrollment verification code is xxxx']])\n",
    "pred = predict(my_texts)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53ad16",
   "metadata": {},
   "source": [
    "Resources:\n",
    "* https://towardsdatascience.com/roc-curve-and-auc-from-scratch-in-numpy-visualized-2612bb9459ab\n",
    "* https://towardsdatascience.com/roc-and-auc-how-to-evaluate-machine-learning-models-in-no-time-fb2304c83a7f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
