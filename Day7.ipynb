{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7efd2c21",
   "metadata": {},
   "source": [
    "# Data manipulations\n",
    "\n",
    "A matrix transformation is a matrix multiplication between a transformation matrix M and a data matrix D that gives you a manipulated data matrix D' as output.\n",
    "\n",
    "We can use matrix multiplications to transform our data (our data points, represented as feature vectors)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce637eac",
   "metadata": {},
   "source": [
    "## But first, some review of dot products\n",
    "\n",
    "What is being done in this cell?\n",
    "\n",
    "* Element-wise multiply [4,5,6] and [1,2,3] and then sum\n",
    "* Element-wise multiply [7,8,9] and [1,2,3] and then sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cccc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([1,2,3])\n",
    "m = np.array([[4,5,6], [7,8,9]])\n",
    "\n",
    "print(m@v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25b9b472",
   "metadata": {},
   "source": [
    "And in this cell?\n",
    "* 32: Element-wise multiply [4,5,6] and [1,2,3] and then sum\n",
    "* 6540: Element-wise multiply [4,5,6] and [10, 100, 1000] and then sum\n",
    "* 50: Element-wise multiply [7,8,9] and [1,2,3] and then sum\n",
    "* 9870: Element-wise multiply [7,8,9] and [10, 100, 1000] and then sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40712d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = np.array([[1,2,3], [10, 100, 1000]])\n",
    "\n",
    "print(m@m2.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ccb0e34",
   "metadata": {},
   "source": [
    "## Load and look at our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3956d96c",
   "metadata": {},
   "source": [
    "Let's load the used car data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "data = np.array(np.genfromtxt('data/vehiclesNumeric.csv', delimiter=',', skip_header=1, dtype=int, encoding=\"utf-8\"))  \n",
    "\n",
    "# get a pandas dataframe for plotting\n",
    "df = pd.DataFrame(data, columns=[\"id\", \"price\", \"year\", \"odometer\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15ff0392",
   "metadata": {},
   "source": [
    "Let's get some **summary statistics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a16a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    return pd.DataFrame([data.min(axis=0), data.max(axis=0), data.mean(axis=0), data.std(axis=0)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd983f32",
   "metadata": {},
   "source": [
    "Let's **reduce the data** to two dimensions, just year and price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are we going to get just those two columns?\n",
    "reducedData = data[:, [1,2]]\n",
    "\n",
    "print(getSummaryStatistics(reducedData))\n",
    "print(getShapeType(reducedData))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d742fd5",
   "metadata": {},
   "source": [
    "Let's plot the used car data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54702667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2d(data):\n",
    "    sns.scatterplot(pd.DataFrame(data[:, [0, 1]], columns=[\"price\", \"year\"]), x=\"year\", y=\"price\").set(title=\"Year vs price for Craigslist used car listings\")\n",
    "    \n",
    "plot2d(reducedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f0a8fc7",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "319be1a1",
   "metadata": {},
   "source": [
    "Translation is a kind of data transformation where we move data around, but each data point stays the same distance away from every other data point.\n",
    "\n",
    "Translation is a two step process:\n",
    "* Add homogeneous coordinate\n",
    "* Do translation as matrix multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e8ef9f",
   "metadata": {},
   "source": [
    "### Add homogeneous coordinate\n",
    "\n",
    "We need to add a dummy column of ones so we can do the matrix multiplication. Why? See https://www.sciencedirect.com/topics/mathematics/homogeneous-coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we append a whole column?\n",
    "homogenizedData = np.append(reducedData, np.array([np.ones(reducedData.shape[0], dtype=int)]).T, axis=1)\n",
    "print(\"homogenized data\")\n",
    "print(getSummaryStatistics(homogenizedData))\n",
    "print(getShapeType(homogenizedData))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d5c47ef",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62a2c455",
   "metadata": {},
   "source": [
    "Let's **translate** that year column so that it too starts at 0.\n",
    "\n",
    "A translation matrix for two-variable data looks like:\n",
    "$$\\begin{pmatrix} 1 & 0 & x \\\\ 0 & 1 & y \\\\ 0 & 0 & 1\\end{pmatrix}$$\n",
    "where $x, y$ are the amount by which you want the $0th$ and $1st$ variables translated, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to define a transformation matrix that will allow us to shift the price variable; this one will be the identity matrix with the translation specified in an extra last column\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=int)\n",
    "translateTransform[1, 2] = -reducedData[:, 1].min()\n",
    "print(\"transformMatrix\")\n",
    "print(translateTransform)\n",
    "\n",
    "print(homogenizedData[0:4])\n",
    "\n",
    "# now we need to do the translation\n",
    "transformedData = (translateTransform@homogenizedData.T).T\n",
    "print(\"after translation, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b5dd9a3",
   "metadata": {},
   "source": [
    "Check:\n",
    "* only the summary statistics for year should have changed\n",
    "* the standard deviation for year should be the same"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5412d6c",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Scaling is kind of data transformation where we increase or decrease the range of one or more variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25be0bcc",
   "metadata": {},
   "source": [
    "### Scaling on its own\n",
    "\n",
    "Let's **scale** that year column so it's months instead of years.\n",
    "\n",
    "A scaling matrix for two-variable data looks like:\n",
    "$$\\begin{pmatrix} x & 0 \\\\ 0 & y \\end{pmatrix}$$\n",
    "where $x, y$ are the amount by which you want the $0th$ and $1st$ variables scaled, respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63221e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleTransform = np.eye(reducedData.shape[1], dtype=float)\n",
    "scaleTransform[1, 1] = 12\n",
    "print(\"transformMatrix\")\n",
    "print(scaleTransform)\n",
    "\n",
    "transformedData = (scaleTransform@reducedData.T).T\n",
    "print(\"after scaling, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de9b55f1",
   "metadata": {},
   "source": [
    "Check:\n",
    "* only the summary statistics for year should have changed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c50feaff",
   "metadata": {},
   "source": [
    "### Scaling together with other transformations\n",
    "\n",
    "If you want to translate *and* scale, you just add the homogeneous coordinate into the scaling matrix too!\n",
    "$$\\begin{pmatrix} x & 0 & 0\\\\ 0 & y & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "scaleTransform[1, 1] = 12\n",
    "print(\"transformMatrix\")\n",
    "print(scaleTransform)\n",
    "\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "translateTransform[1, 2] = -reducedData[:, 1].min()\n",
    "print(\"transformMatrix\")\n",
    "print(translateTransform)\n",
    "\n",
    "transformMatrix = translateTransform@scaleTransform\n",
    "\n",
    "transformedData = (transformMatrix@homogenizedData.T).T\n",
    "print(\"after scaling, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "168227d8",
   "metadata": {},
   "source": [
    "Check:\n",
    "* Although we added the homogeneous coordinate, the scaling produced the same output as before"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7cf73e8",
   "metadata": {},
   "source": [
    "## Global max-min normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3737e93b",
   "metadata": {},
   "source": [
    "Let's try **global (max-min) normalization**\n",
    "\n",
    "Here is how that works:\n",
    "1. subtract the global minimum from each datapoint\n",
    "2. divide by the global range (max - min)\n",
    "\n",
    "The transformation matrix for two variables looks like:\n",
    "$$\\begin{pmatrix} \\frac{1}{(max(data)-min(data))} & 0 & -min(data) \\\\ 0 & \\frac{1}{(max(data)-min(data))} & -min(data) \\\\ 0 & 0 & 1\\end{pmatrix}$$\n",
    "\n",
    "What does this look like in terms of scaling and translation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c811513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the global minimum from each datapoint\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "for i in range(reducedData.shape[1]):\n",
    "    translateTransform[i, 2] = -reducedData.min()\n",
    "print(\"translateTransform\")\n",
    "print(translateTransform)\n",
    "\n",
    "# divide by the global range\n",
    "scaleTransform = np.eye(3, 3)\n",
    "scaleTransform[0, 0] = 1 / (reducedData.max() - reducedData.min())\n",
    "scaleTransform[1, 1] = 1 / (reducedData.max() - reducedData.min())\n",
    "scaleTransform[2, 2] = 1 / (reducedData.max() - reducedData.min())\n",
    "print(\"scaleTransform\")\n",
    "print(scaleTransform)\n",
    "\n",
    "# when we do a series of transformations, first we multiply the smaller transformation matrices, and only at the end the result of that with the larger data matrix (more efficient!)\n",
    "totalTransform = scaleTransform@translateTransform\n",
    "print(\"transformMatrix\")\n",
    "print(\"shape\\n\", getShapeType(totalTransform))\n",
    "print(totalTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedData = (totalTransform@homogenizedData.T).T\n",
    "print(\"after global normalization, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1ac23d2",
   "metadata": {},
   "source": [
    "What seems weird to you about this process? What seems solid?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "079615b5",
   "metadata": {},
   "source": [
    "## Per-variable max-min normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "325b72cb",
   "metadata": {},
   "source": [
    "Let's try **max-min normalization per variable**.\n",
    "\n",
    "The transformation matrix for two variables, $x$ and $y$, looks like:\n",
    "$$\\begin{pmatrix} \\frac{1}{(max(x)-min(x))} & 0 & -min(x) \\\\ 0 & \\frac{1}{(max(y)-min(y))} & -min(y) \\\\ 0 & 0 & 1\\end{pmatrix}$$\n",
    "\n",
    "What does this look like in terms of scaling and translation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b538123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before per variable normalization, homogenizedData\")\n",
    "print(getSummaryStatistics(homogenizedData))\n",
    "\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "translateTransform[:, 2] = np.array([-homogenizedData[:, 0].min(), -homogenizedData[:, 1].min(), 1])\n",
    "scaleTransform = np.eye(homogenizedData.shape[1]) * [1 / (homogenizedData[:, 0].max() - homogenizedData[:, 0].min()), 1 / (homogenizedData[:, 1].max() - homogenizedData[:, 1].min()), 1]\n",
    "\n",
    "totalTransform = scaleTransform@translateTransform\n",
    "print(\"transformMatrix\")\n",
    "print(totalTransform)\n",
    "\n",
    "\n",
    "transformedData = (totalTransform @ homogenizedData.T).T\n",
    "print(\"after per variable normalization, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c55a9ce",
   "metadata": {},
   "source": [
    "What is good about this way of normalizing our data? What do we not like?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41dcb755",
   "metadata": {},
   "source": [
    "## Z-scoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cad3b1f",
   "metadata": {},
   "source": [
    "Max-min normalization will move everything to the unit square, but that may not help me see things more clearly. What if I try **z-scoring**: normalizing each feature by its mean and standard deviation instead?\n",
    "\n",
    "The transformation matrix for two variables, $x$ and $y$, looks like:\n",
    "$$\\begin{pmatrix} \\frac{1}{(std(x))} & 0 & -mean(x) \\\\ 0 & \\frac{1}{(std(y))} & -mean(y) \\\\ 0 & 0 & 1\\end{pmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2370c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before z-scoring, homogenizedData\")\n",
    "print(getSummaryStatistics(homogenizedData))\n",
    "\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "translateTransform[:, 2] = np.array([-homogenizedData[:, 0].mean(), -homogenizedData[:, 1].mean(), 1], dtype=float)\n",
    "print(translateTransform)\n",
    "scaleTransform = np.eye(homogenizedData.shape[1]) * [1 / homogenizedData[:, 0].std(), 1 / homogenizedData[:, 1].std(), 1]\n",
    "\n",
    "totalTransform = scaleTransform@translateTransform\n",
    "print(\"transformMatrix\")\n",
    "print(totalTransform)\n",
    "\n",
    "transformedData = (totalTransform@homogenizedData.T).T\n",
    "print(\"after z-scoring, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fde1145d",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "* What if I want to *mean center* my data, or make the mean point zero?\n",
    "* What if I want to *mean center* and normalize so that the data's range is [-1, 1]?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73b122e9",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "There are some nice web-based visualizers that show you how scaling and rotation work (rotation comes next week!). Here is one where you can upload your own picture:\n",
    "* https://web.ma.utexas.edu/users/ysulyma/matrix/\n",
    "\n",
    "And here is one that walks through the matrix multiply with you:\n",
    "* https://www.cs.usfca.edu/~galles/visualization/RotateScale3D.html\n",
    "* https://www.cs.usfca.edu/~galles/visualization/RotateScale2D.html\n",
    "\n",
    "And finally, here is an Observable notebook that also reviews the matrix multiply:\n",
    "* https://observablehq.com/@noonat/transformation-matrices\n",
    "\n",
    "Happy playing!\n",
    "\n",
    "## Resources\n",
    "\n",
    "* https://staff.fnwi.uva.nl/r.vandenboomgaard/IPCV20162017/LectureNotes/MATH/homogenous.html\n",
    "* https://www.informit.com/articles/article.aspx?p=2854376&seqNum=8\n",
    "* https://towardsdatascience.com/normalization-techniques-in-python-using-numpy-b998aa81d754\n",
    "* https://www.machinecurve.com/index.php/2020/11/19/how-to-normalize-or-standardize-a-dataset-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
