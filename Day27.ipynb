{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b250b67f",
   "metadata": {},
   "source": [
    "# The One Goal for Today\n",
    "\n",
    "To understand Bayes' rule."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8387f26",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Today we are going to review terminology for talking about probabilities, and then talk about Bayes' rule. \n",
    "\n",
    "How is this relevant to data analysis, particularly supervised modeling? kNN is very flexible, but it is also **slow**. Every time we want to classify a new datapoint, we have to calculate the distance between it and all the data points in the training data and then sort those distances. \n",
    "\n",
    "We will use Bayes' rule to develop a second, faster approach to supervised modeling for data with a qualitative dependent variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94b3dec",
   "metadata": {},
   "source": [
    "# Data samples\n",
    "\n",
    "Now, in data analysis we very rarely have *all the data*. In most cases, we have a *sample* of the data that we assume / hope / know to be big enough to generalize over. \n",
    "\n",
    "If dataset A (or B) above were *all the data* we could calculate actual probabilities; for example, the probability that A[0, 0] = 4. \n",
    "\n",
    "Even if A (or B) is a *sample* of the data, we still calculate relative frequencies, and if the sample is large enough they will approximate probabilities. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae44bff6",
   "metadata": {},
   "source": [
    "# Review of probability\n",
    "\n",
    "## Probability of independent events\n",
    "\n",
    "Let's imagine we have two dice, die $A$ and die $B$. \n",
    "* *What is the probability of rolling a 4 on die $A$, $P(A=4)$*?\n",
    "* *What is the probability of rolling a 4 on die $B$, $P(B=3)$*?\n",
    "* *What is the probability of rolling a 4 on die $A$ _and_ a 4 on die *B*, $P(A=4, B=3)$?\n",
    "\n",
    "The probability of rolling a 4 on die $A$ is *independent* of the probability of rolling a 4 on die *B*. \n",
    "\n",
    "So $P(A=4,B=3) = P(A=4)*P(B=3)$.\n",
    "\n",
    "# Conditional probabilities\n",
    "\n",
    "Sometimes I carry an umbrella to work. Let's imagine that I look out my window each morning and if I see rain, I am more likely to carry my umbrella to work. Here's two work weeks of my life, with the weather each day (R = rain, S = sun) and whether I carried an umbrella (U = carried an umbrella):\n",
    "| M | T | W | R | F | M | T | W | R | F |\n",
    "| - | - | - | - | - | - | - | - | - | - |\n",
    "| R | S | R | R | S | S | R | R | R | S |\n",
    "| U |   | U |   | U |   | U | U |   |   |\n",
    "\n",
    "The probability of me carrying an umbrella to work is *not* independent of the probability that the weather is rainy:\n",
    "* What's the probability that the weather is rainy, $P(W=R)$? \n",
    "* What's the probability that I carry my umbrella to work, $P(C=U)$? \n",
    "* Is the probability that I carry my umbrella to work _and_ the weather is rainy, $P(W=R, C=U)$, equal to $P(W=R)*P(C=U)$? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "246848e5",
   "metadata": {},
   "source": [
    "# Bayes' rule\n",
    "\n",
    "Let's look deeper at $P(W=R, C=U)$. Let's calculate it two ways:\n",
    "\n",
    "Way 1:\n",
    "* What's the probability that the weather is rainy, $P(W=R)$? \n",
    "* What's the probability that I carry my umbrella to work _given that_ the weather is rainy, $P(C=U|W=R)$? \n",
    "* What's the probability of $P(W=R, C=U)$? \n",
    "\n",
    "Way 2:\n",
    "* What's the probability that I carry my umbrella to work, $P(C=U)$? \n",
    "* What's the probability that the weather is rainy _given that_ I carry my umbrella to work, $P(W=R|C=U)$? \n",
    "* What's the probability of $P(W=R, C=U)$? \n",
    "\n",
    "That's interesting! So $P(W=R)*P(C=U|W=R) = P(C=U)*P(W=R|C=U)$. Let's rearrange: $P(C=U|W=R) = \\frac{P(C=U)*P(W=R|C=U)}{P(W=R)}$. \n",
    "\n",
    "This is a *universal rule* called Bayes' rule. Bayes' rule tells us how to update the probability of an event using *prior* knowledge about things (evidence) that might influence that event. In fact, there is a whole branch of statistics (Bayesian statistics) based on Bayes' rule. \n",
    "\n",
    "Let's restate Bayes' rule a little; instead of $P(C=U|W=R)$ we can just say $P(U|R)$. So $P(U|R) = \\frac{P(U)*P(R|U)}{P(R)}$. $P(U)$ is the *prior* on $U$, $P(R|U)$ is the *likelihood* (of $R$ given $U$), $P(R)$ is the *evidence* or *normalization*, and $P(U|R)$ is the *posterior*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76364429",
   "metadata": {},
   "source": [
    "## Bayes' rule example\n",
    "\n",
    "Now let's do an example using these tasty peanut M&Ms I have here. In my cup, there are three M&Ms. They might all be yellow, they might all be blue, or some of them might be yellow and some blue. In other words, here are the possibilities:\n",
    "* 3 blues, 0 yellows (3b0y)\n",
    "* 2 blues, 1 yellow (2b1y)\n",
    "* 1 blue, 2 yellows (1b2y)\n",
    "* 0 blues, 3 yellows (0b3y)\n",
    "\n",
    "Without any *evidence*, all four of those possibilities are equally likely. So let's accumulate some *evidence*. I'm going to:\n",
    "1. Take one M&M from the cup (without looking into the cup!).\n",
    "2. Write down the color of the M&M.\n",
    "3. Put the M&M back (do **NOT** eat the M&M!!).\n",
    "\n",
    "I draw *one* M&M from the cup, without looking into the cup. Then, *given* that one M&M, let's see if we can estimate the probability that there are 2 blues and 1 yellow:\n",
    "\n",
    "**2b1y**\n",
    "* $P(2b1y | 1?) = P(2b1y)*P(1?|2b1y) / P(1?)$. \n",
    "* $P(2b1y) = 1/4$.  \n",
    "* $P(1?|2b1y) = ??$.\n",
    "* $P(1?) = P(1?|3b0y)*P(3b0y) + P(1?|2b1y)*P(2b1y) + P(1?|1b2y)*P(1b2y) + P(1?|0b3y)*P(0b3y) = ??$.\n",
    "\n",
    "$P(2b1y | ?b) = ??$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42368bf",
   "metadata": {},
   "source": [
    "Let's repeat for the other three possible outcomes:\n",
    "\n",
    "__1b2y__\n",
    "\n",
    "* $P(1b2y | 1?) = P(1b2y)*P(1?|1b2y) / P(1?)$. \n",
    "* $P(1b2y) = 1/4$.  \n",
    "* $P(1?|1b2y) = ??$.\n",
    "* $P(1?) = P(1?|3b0y)*P(3b0y) + P(1?|2b1y)*P(2b1y) + P(1?|1b2y)*P(1b2y) + P(1?|0b3y)*P(0b3y) = ??$.\n",
    "\n",
    "So $P(1b2y | 1?) = ??$.\n",
    "\n",
    "__3b__\n",
    "* $P(3b0y | 1?) = P(3b0y)*P(1?|3b0y) / P(1?)$. \n",
    "* $P(3b0y) = 1/4$.  \n",
    "* $P(1?|3b0y) = ??$.\n",
    "* $P(1?) = P(1?|3b0y)*P(3b0y) + P(1?|2b1y)*P(2b1y) + P(1?|1b2y)*P(1b2y) + P(1?|0b3y)*P(0b3y) = ??$.\n",
    "\n",
    "So $P(3b0y | 1?) = ??$.\n",
    "\n",
    "__3y__\n",
    "* $P(0b3y | 1?) = P(0b3y)*P(1?|0b3y) / P(1?)$. \n",
    "* $P(0b3y) = 1/4$.  \n",
    "* $P(1?|0b3y) = ??$.\n",
    "* $P(1?) = P(1?|3b0y)*P(3b0y) + P(1?|2b1y)*P(2b1y) + P(1?|1b2y)*P(1b2y) + P(1?|0b3y)*P(0b3y) = ??$.\n",
    "\n",
    "So $P(0b3y | 1?) = ??$.\n",
    "\n",
    "Sanity check: does the sum of all four probabilities equal 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414784d",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Now you do one! Each of you will have a cup with *4* M&Ms. \n",
    "\n",
    "* What are the possible outcomes for color combinations in your cup?\n",
    "* Draw one M&M. Given this M&M, what is the probability of each combination of color combination in your cup?\n",
    "\n",
    "Worked out below:\n",
    "\n",
    "* $P(1x) = P(1x|4x0y)*P(4x0y) + P(1x|3x1y)*P(3x1y) + P(1x|2x2y)*P(2x2y) + P(1x|1x3y)*P(1x3y) + P(1x|0x4y)*P(0x4y) = 1*1/5 + 3/4*1/5 + 1/2*1/5 + 1/4*1/5 + 0 = 1/5 + 3/20 + 1/10 + 1/20 = 1/2$.\n",
    "\n",
    "* $P(4x0y | 1x) = (P(4x0y)*P(1x|4x0y)) / P(1x)$. \n",
    "* $P(4x0y) = 1/5$ (possibilities: 4x0y, 3x1y, 2x2y, 1x3y, 0x4y)  \n",
    "* $P(1x|4x0y) = 1$.\n",
    "\n",
    "So $P(4x0y | 1x) = 1/5*1 / 1/2 = 2/5$.\n",
    "\n",
    "* $P(3x1y | 1x) = (P(3x1y)*P(1x|3x1y)) / P(1x)$. \n",
    "* $P(3x1y) = 1/5$ (possibilities: 4x0y, 3x1y, 2x2y, 1x3y, 0x4y)  \n",
    "* $P(1x|3x1y) = 3/4$.\n",
    "\n",
    "So $P(3x1y | 1x) = 1/5*3/4 / 1/2 = 3/10$.\n",
    "\n",
    "* $P(2x2y | 1x) = (P(2x2y)*P(1x|2x2y)) / P(1x)$. \n",
    "* $P(2x2y) = 1/5$ (possibilities: 4x0y, 3x1y, 2x2y, 1x3y, 0x4y)  \n",
    "* $P(1x|2x2y) = 1/2$.\n",
    "\n",
    "So $P(2x2y | 1x) = 1/5*1/2 / 1/2 = 1/5$.\n",
    "\n",
    "* $P(1x3y | 1x) = (P(1x3y)*P(1x|4x0y)) / P(1x)$. \n",
    "* $P(1x3y) = 1/5$ (possibilities: 4x0y, 3x1y, 2x2y, 1x3y, 0x4y)  \n",
    "* $P(1x|1x3y) = 1/4$.\n",
    "\n",
    "So $P(1x3y | 1x) = 1/5*1/4 / 1/2 = 1/10$.\n",
    "\n",
    "* $P(0x4y | 1x) = 0$. \n",
    "\n",
    "Sanity check: 1/10 + 1/5 + 3/10 + 2/5 = 10/10!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
