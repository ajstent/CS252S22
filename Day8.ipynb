{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7efd2c21",
   "metadata": {},
   "source": [
    "# Data manipulations\n",
    "\n",
    "A matrix transformation is a matrix multiplication between a transformation matrix M and a data matrix D that gives you a manipulated data matrix D' as output.\n",
    "\n",
    "We can use matrix multiplications to transform our data (our data points, represented as feature vectors)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ccb0e34",
   "metadata": {},
   "source": [
    "## Load and look at our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3956d96c",
   "metadata": {},
   "source": [
    "Let's load the used car data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "data = np.array(np.genfromtxt('data/vehiclesNumeric.csv', delimiter=',', skip_header=1, dtype=int, encoding=\"utf-8\", usecols=[1,2,3]))  \n",
    "\n",
    "# get a pandas dataframe for plotting\n",
    "df = pd.DataFrame(data, columns=[\"price\", \"year\", \"odometer\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15ff0392",
   "metadata": {},
   "source": [
    "Let's get some **summary statistics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a16a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    return pd.DataFrame([data.min(axis=0), data.max(axis=0), data.mean(axis=0), data.std(axis=0)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d742fd5",
   "metadata": {},
   "source": [
    "Let's plot the used car data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54702667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2d(data):\n",
    "    sns.scatterplot(pd.DataFrame(data[:, [0, 1]], columns=[\"price\", \"year\"]), x=\"year\", y=\"price\").set(title=\"Year vs price for Craigslist used car listings\")\n",
    "    \n",
    "plot2d(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62a2c455",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "A translation matrix for two-variable data looks like:\n",
    "$$\\begin{pmatrix} 1 & 0 & x \\\\ 0 & 1 & y \\\\ 0 & 0 & 1\\end{pmatrix}$$\n",
    "where $x, y$ are the amount by which you want the $0th$ and $1st$ variables translated, respectively.\n",
    "\n",
    "A scaling matrix for two-variable data looks like:\n",
    "$$\\begin{pmatrix} x & 0 \\\\ 0 & y \\end{pmatrix}$$\n",
    "where $x, y$ are the amount by which you want the $0th$ and $1st$ variables scaled, respectively. \n",
    "\n",
    "You can combine them if you add a third column to the scaling matrix with all 0s except for the last item (a 1):\n",
    "$$\\begin{pmatrix} x & 0 & 0 \\\\ 0 & y & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7cf73e8",
   "metadata": {},
   "source": [
    "## Global max-min normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d89af79a",
   "metadata": {},
   "source": [
    "Add homogenized coordinate so we can translate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we append a whole column?\n",
    "homogenizedData = np.append(data, np.array([np.ones(data.shape[0], dtype=int)]).T, axis=1)\n",
    "print(\"homogenized data\")\n",
    "print(getSummaryStatistics(homogenizedData))\n",
    "print(getShapeType(homogenizedData))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3737e93b",
   "metadata": {},
   "source": [
    "Visualization and modeling will be much easier if the ranges of my data are more similar. Let's just transform our data to be in the range [0, 1].\n",
    "\n",
    "Here are two ways to get there.\n",
    "\n",
    "First, let's try **global (max-min) normalization**.\n",
    "\n",
    "Here is how that works:\n",
    "1. subtract the global minimum from each datapoint\n",
    "2. divide by the global range (max - min)\n",
    "\n",
    "The transformation matrix for two variables looks like:\n",
    "$$\\begin{pmatrix} \\frac{1}{(max(data)-min(data))} & 0 & -min(data) \\\\ 0 & \\frac{1}{(max(data)-min(data))} & -min(data) \\\\ 0 & 0 & 1\\end{pmatrix}$$\n",
    "\n",
    "What does this look like in terms of scaling and translation?\n",
    "\n",
    "What does the transformation matrix look like, specifically, for our data?\n",
    "$$\\begin{pmatrix} \\frac{1}{9999999} & 0 & 0 & -0 \\\\ 0 & \\frac{1}{9999999} & 0 & -0 \\\\ 0 & 0 & \\frac{1}{9999999} & -0 \\\\ 0 & 0 & 0 & 1\\end{pmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c811513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the global minimum from each datapoint\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "for i in range(data.shape[1]):\n",
    "    ## the notebook you got for class had \"translateTransform[1, 2]\". A few great teams said, hey, Dr. Stent, this should be the column indexed at 3 for 3-dimensional input data! Always point out when you think you see a bug!\n",
    "    translateTransform[i, 3] = -data.min()\n",
    "print(\"translateTransform\")\n",
    "print(translateTransform)\n",
    "\n",
    "# divide by the global range\n",
    "scaleTransform = np.eye(homogenizedData.shape[1])\n",
    "for i in range(data.shape[1]):\n",
    "    scaleTransform[i, i] = 1/(data.max()-data.min())\n",
    "print(\"scaleTransform\")\n",
    "print(scaleTransform)\n",
    "\n",
    "# when we do a series of transformations, first we multiply the smaller transformation matrices, and only at the end the result of that with the larger data matrix (more efficient!)\n",
    "totalTransform = scaleTransform@translateTransform\n",
    "print(\"transformMatrix\")\n",
    "print(\"shape\\n\", getShapeType(totalTransform))\n",
    "print(totalTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedData = (totalTransform@homogenizedData.T).T\n",
    "print(\"after global normalization, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1ac23d2",
   "metadata": {},
   "source": [
    "What seems weird to you about this process? What seems solid?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "079615b5",
   "metadata": {},
   "source": [
    "## Per-variable max-min normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "325b72cb",
   "metadata": {},
   "source": [
    "Here's another way. Let's try **max-min normalization per variable**.\n",
    "\n",
    "The transformation matrix for two variables, $x$ and $y$, looks like:\n",
    "$$\\begin{pmatrix} \\frac{1}{(max(x)-min(x))} & 0 & -min(x) \\\\ 0 & \\frac{1}{(max(y)-min(y))} & -min(y) \\\\ 0 & 0 & 1\\end{pmatrix}$$\n",
    "\n",
    "What does this look like in terms of scaling and translation?\n",
    "\n",
    "What does the transformation matrix look like for our data, specifically?\n",
    "$$\\begin{pmatrix} \\frac{1}{55000} & 0 & 0 & -0 \\\\ 0 & \\frac{1}{22} & 0 & -1999 \\\\ 0 & 0 & \\frac{1}{9999999} & -0 \\\\ 0 & 0 & 0 & 1\\end{pmatrix}$$\n",
    "(NB in class we just divided by the max, which works great as long as the min is 0, but for YEAR doesn't work out so well. Use max-min! **Speak up when you see a mistake!**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b538123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before per variable normalization, homogenizedData\")\n",
    "print(getSummaryStatistics(homogenizedData))\n",
    "\n",
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "for i in range(data.shape[1]):\n",
    "    ## the notebook you got for class had \"translateTransform[1, 2]\". A few great teams said, hey, Dr. Stent, this should be the column indexed at 3 for 3-dimensional input data! Always point out when you think you see a bug!\n",
    "    translateTransform[i, 3] = -data[:, i].min()\n",
    "\n",
    "scaleTransform = np.eye(homogenizedData.shape[1], dtype=float)\n",
    "for i in range(data.shape[1]):\n",
    "    scaleTransform[i, i] = 1/(data[:, i].max()-data[:, i].min())\n",
    "\n",
    "totalTransform = scaleTransform@translateTransform\n",
    "print(\"transformMatrix\")\n",
    "print(totalTransform)\n",
    "\n",
    "transformedData = (totalTransform @ homogenizedData.T).T\n",
    "print(\"after per variable normalization, transformedData\")\n",
    "print(getSummaryStatistics(transformedData))\n",
    "print(getShapeType(transformedData))\n",
    "plot2d(transformedData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c55a9ce",
   "metadata": {},
   "source": [
    "What is good about this way of normalizing our data? What do we not like?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fde1145d",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "* What if I want to *mean center* my data, or make the mean point zero?\n",
    "* What if I want to *mean center* and normalize so that the data's range is [-1, 1]?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73b122e9",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "There are some nice web-based visualizers that show you how scaling and rotation work (rotation comes next week!). Here is one where you can upload your own picture:\n",
    "* https://web.ma.utexas.edu/users/ysulyma/matrix/\n",
    "\n",
    "And here is one that walks through the matrix multiply with you:\n",
    "* https://www.cs.usfca.edu/~galles/visualization/RotateScale3D.html\n",
    "* https://www.cs.usfca.edu/~galles/visualization/RotateScale2D.html\n",
    "\n",
    "And finally, here is an Observable notebook that also reviews the matrix multiply:\n",
    "* https://observablehq.com/@noonat/transformation-matrices\n",
    "\n",
    "Happy playing!\n",
    "\n",
    "## Resources\n",
    "\n",
    "* https://staff.fnwi.uva.nl/r.vandenboomgaard/IPCV20162017/LectureNotes/MATH/homogenous.html\n",
    "* https://www.informit.com/articles/article.aspx?p=2854376&seqNum=8\n",
    "* https://towardsdatascience.com/normalization-techniques-in-python-using-numpy-b998aa81d754\n",
    "* https://www.machinecurve.com/index.php/2020/11/19/how-to-normalize-or-standardize-a-dataset-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cc901",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
