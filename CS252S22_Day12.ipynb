{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243b190",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The first three steps in data science are to:\n",
    "* find your data\n",
    "* look at your data\n",
    "* clean your data\n",
    "\n",
    "Today we will keep working with the set of Craigslist listings for used Mazda 3s. (!!)\n",
    "\n",
    "This dataset is the Mazda 3 subset from https://www.kaggle.com/austinreese/craigslist-carstrucks-data after some cleanup (basically, I selected all the variants of Mazda 3 in the model column, and then removed some columns).\n",
    "\n",
    "Take a look at it in data/mazdas.csv!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3775ce",
   "metadata": {},
   "source": [
    "Now we will load this dataset. I'm going to load it the unpleasant way (rather than using the Data class), because I want to use those nonnumeric colums. \n",
    "\n",
    "Because our numpy arrays all have to be the same type, we first need to:\n",
    "* figure out which columns we want\n",
    "* define some converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just does pattern matching\n",
    "import re\n",
    "\n",
    "def conditionConverter(x):\n",
    "    values = ['', 'new', 'like new', 'excellent', 'good', 'fair', 'salvage']\n",
    "    return values.index(x)\n",
    "\n",
    "def titleConverter(x):\n",
    "    values = ['', 'clean', 'lien', 'rebuilt','salvage']\n",
    "    return values.index(x)\n",
    "\n",
    "def transmissionConverter(x):\n",
    "    values = ['', 'automatic', 'manual', 'other']\n",
    "    return values.index(x)\n",
    "\n",
    "def typeConverter(x):\n",
    "    if re.match(r'(sedan|coupe)', x):\n",
    "        return 1\n",
    "    elif re.match(r'(mini-van|hatchback|wagon|SUV)', x):\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "def colorConverter(x):\n",
    "    values = ['', 'grey', 'white', 'black', 'blue', 'orange', 'purple', 'red', 'green', 'brown', 'custom', 'silver']\n",
    "    if x in values:\n",
    "        return values.index(x)\n",
    "    else:\n",
    "        print(\"couldn't find |\" + x + \"|\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca359103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# This dataset is the mazda subsample from https://www.kaggle.com/austinreese/craigslist-carstrucks-data after some cleanup\n",
    "\n",
    "columns = [\"price\", \"age\", \"condition\", \"odometer\", \"title_type\", \"transmission\", \"type\", \"color\"]\n",
    "data = np.array(np.genfromtxt('data/mazdas.csv', delimiter=',', usecols=(1,2,5,6,7,8,9,10), converters={5: conditionConverter, 7: titleConverter, 8: transmissionConverter, 9: typeConverter, 10: colorConverter}, skip_header=2, dtype=int, encoding='utf-8'))  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5a5ca",
   "metadata": {},
   "source": [
    "Let's do a pairplot so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ceb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=columns)\n",
    "seaborn.pairplot(df, y_vars = columns[0], x_vars = columns[1:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef809d3",
   "metadata": {},
   "source": [
    "Let's get some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    return np.array([data.max(axis=0), data.min(axis=0), data.mean(axis=0, dtype=int)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc62d6b",
   "metadata": {},
   "source": [
    "Let's calculate *correlations* between price and the other variables. (Remind me what correlation values vary between?)\n",
    "\n",
    "** Consider: correlations between *all pairs of variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(columns)):\n",
    "    print(columns[i], np.corrcoef(data[:, 0], data[:, i], rowvar=True)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b850ff",
   "metadata": {},
   "source": [
    "## Let's review regression\n",
    "\n",
    "Regression allows us to:\n",
    "* determine the *nature* of a relationship between one (or more!) independent variables and a dependent variable\n",
    "* determine the *strength* of the relationship\n",
    "\n",
    "Regression *fits* a function to a dataset.\n",
    "\n",
    "Regression is *not* the same as interpolation: we don't want to fit so closely that we exactly pass through each data point, but rather fit so that we generalize over the data. Why is this?\n",
    "* because the data sets we have are not *all* the data, but a *sample* of the data, and other samples may be somewhat different\n",
    "* because we want to be able to *explain* relationships between variables\n",
    "\n",
    "Both of these require some generalization/abstraction away from the actual data.\n",
    "\n",
    "Okay, so we need some functions; we need a method for making the function \"fit\" the data; and we need a measure of how \"good\" the fit is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac8405",
   "metadata": {},
   "source": [
    "## What kinds of functions can we fit? \n",
    "\n",
    "We are going to start with *linear regression*. What type of function do we fit when we do linear regression? A linear function! You might see it written like $$F(x_i) = b + mx_i$$ or like $$\\hat{y}_i = b+ mx_i$$It's called linear because when you plot it you get a line that crosses 0 at $b$ (the \"intercept\") and has slope $m$.\n",
    "\n",
    "Note that this function tries to calculate one variable ($y$) as a function of one other variable ($x$). Next week, we will look at functions that calculate $y$ as a function of multiple other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotxyyhat(x, y, m, b):\n",
    "    plt.plot(x, y, 'o', label='data')\n",
    "    yhat = m*x + b\n",
    "    plt.plot(x, yhat, label='least squares fit, $y = mx + b$')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(framealpha=1, shadow=True)\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f44154",
   "metadata": {},
   "source": [
    "## What does it mean to *fit* a function? \n",
    "\n",
    "Now let's talk about methods for making the function \"fit\" the data. We know $x$, and we know $y$. We do *not* know the values for $b$ or $m$; that's what we need to figure out. In order to do that, we need a notion of \"goodness of fit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df7d93",
   "metadata": {},
   "source": [
    "## How do we measure how \"good\" the fit is?\n",
    "\n",
    "If we have a function and a set of data points, how well does the function fit the data? \n",
    "\n",
    "The \"bit left over\" or the \"distance\", which we call the *residual*, is often calculated as: $$r_i = y_i - F(x_i)$$ (or, $r_i = y_i - \\hat{y}_i$).\n",
    "\n",
    "And how can we combine these differences? We could:\n",
    "* Take the average, median, min or max of the distances\n",
    "* Take the average, median, min or max of the absolute distances\n",
    "* Take the sum of the absolute distances\n",
    "* Take the mean of the sum of the square of the distances (MSSE, or *mean sum of squared error*):\n",
    "$$MSSE = 1 / N \\sum_{i=1}^N (r_i)^2 = 1/N \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be more elegantly written if x and y are definitely numpy arrays; how?\n",
    "def msse(x, y, m, b):\n",
    "    if len(x) != len(y):\n",
    "        print(\"Need x and y to be the same length!\")\n",
    "        return 0\n",
    "    yhat = [m*xi + b for xi in x]\n",
    "    r = 0.0\n",
    "    for i in range(len(x)):\n",
    "        r += (float(y[i]) - float(yhat[i]))*(float(y[i]) - float(yhat[i]))\n",
    "    r = (1 / len(x)) * r\n",
    "    return r\n",
    "\n",
    "# what happens if our slope is 0 and our intercept is the mean value for price?\n",
    "print(msse(data[:, 1], data[:, 0], 0, data[:, 0].mean()))\n",
    "# let's see if we can do better than just using the mean..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9278a",
   "metadata": {},
   "source": [
    "Okay, so to calculate $m$ and $b$, we need to _minimize_ $MSSE$ with respect to each. We do this using a method called [least squares](https://en.wikipedia.org/wiki/Least_squares) (see also [least squares](https://www.wolframalpha.com/input?i=least+squares). We take the partial derivatives of $MSSE$ with respect to $m$ and $b$, setting to 0 (the minimum) and solving (*please check my math!*):\n",
    "* partial derivative of $MSSE$ ($p$) with respect to $m$: $$\\frac{\\partial p}{\\partial m} = 0 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial m} (y_i - F(x_i))^2 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial m} (y_i - (m x_i + b))^2 = \\sum_{i=1}^N -2 x_i (y_i - (m x_i + b)) = \\sum_{i=1}^N x_i y_i -m \\sum_{i=1}^N {x_i}^2 - b \\sum_{i=1}^N x_i$$\n",
    "* partial derivative of $MSSE$ ($p$) with respect to $b$: $$\\frac{\\partial p}{\\partial b} = 0 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial b} (y_i - F(x_i))^2 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial b} (y_i - (m x_i + b))^2 = \\sum_{i=1}^N -2 (y_i - (m x_i + b)) = \\sum_{i=1}^N y_i - m \\sum_{i=1}^N x_i  - b N$$\n",
    "\n",
    "So then, \n",
    "$$ m = \\frac{\\sum_{i=1}^N x_i \\sum_{i=1}^N y_i - N \\sum_{i=1}^N x_i y_i}{(\\sum_{i=1}^N x_i)^2 - N \\sum_{i=1}^N {x_i}^2}$$\n",
    "$$ b = \\frac{\\sum_{i=1}^N x_i \\sum_{i=1}^N x_i y_i -\\sum_{i=1}^N {x_i}^2 \\sum_{i=1}^N y_i}{{(\\sum_{i=1}^N x_i})^2 - N\\sum_{i=1}^N {x_i}^2}$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^N {x_i}^2 & \\sum_{i=1}^N x_i \\\\\n",
    "\\sum_{i=1}^N x_i & N\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "m \\\\\n",
    "b\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^N x_i y_i \\\\\n",
    "\\sum_{i=1}^N y_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now this is something we can calculate using matrix math:\n",
    "$$F(x_i) = b + m x_i = (1, X_i) \\cdot (b, m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cca9b",
   "metadata": {},
   "source": [
    "The function \"lstsq\" in the scipy package's linalg (linear algebra) subpackage\n",
    "fits a linear regression using least squares. It gives us predicted $y$ values $\\hat{y}$ and residuals for each $\\hat{y}$. Let's try it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8893fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sp_la\n",
    "\n",
    "def fit(data, independent, dependent):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[:, independent]\n",
    "    print(getSummaryStatistics(x))\n",
    "    print(getShapeType(x))\n",
    "\n",
    "    # We add a column of 1s for the intercept\n",
    "    A = x[:, np.newaxis]**[0, 1]\n",
    "    print(getSummaryStatistics(A))\n",
    "    print(getShapeType(A))\n",
    "\n",
    "    # This is the dependent variable \n",
    "    y = data[:, dependent]\n",
    "    print(getSummaryStatistics(y))\n",
    "    print(getShapeType(y))\n",
    "\n",
    "    # This is the regression coefficients that were fit, plus some other results\n",
    "    c, res, _, _ = sp_la.lstsq(A, y)\n",
    "\n",
    "    return c, res\n",
    "\n",
    "c, res = fit(data, 1, 0)\n",
    "# this is b and m!\n",
    "print(c)\n",
    "plotxyyhat(data[:, 1], data[:, 0], c[1], c[0])\n",
    "print(msse(data[:, 1], data[:, 0], c[1], c[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b904a",
   "metadata": {},
   "source": [
    "## And, this is a function we can use to predict the $y$ (calculate the $\\hat{y}$) for new $x$s, so it's a *model*!\n",
    "\n",
    "For example, my car was a 2018 Mazda 3, so what should its Craigslist price be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c[1]*2010+c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55025d54",
   "metadata": {},
   "source": [
    "*What about your Mazda 3s??*\n",
    "\n",
    "Of course, this model is based on *historical* car prices, and what has happened over the past year?\n",
    "\n",
    "Let's collect all our Mazda 3s and make them into a dataset, then let's use that dataset to \"evaluate\" our model:\n",
    "* We will take the model we fit (the prediction function we fit) to our *training data*\n",
    "* We will use it to predict values for the new data, the *test data*\n",
    "* We will measure how well the model does at predicting\n",
    "\n",
    "Just above when we fit the model, we calculated $$ A \\cdot \\vec{c} = \\vec{\\hat{y}} $$\n",
    "and we knew $A$ and $\\vec{y}$.\n",
    "\n",
    "Now we know $A$ and $\\vec{c}$ and we want to calculate $\\vec{\\hat{y}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, independent, c):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[:, independent]\n",
    "    print(getSummaryStatistics(x))\n",
    "    print(getShapeType(x))\n",
    "\n",
    "    # We add a column of 1s for the intercept\n",
    "    A = x[:, np.newaxis]**[0, 1]\n",
    "    print(getSummaryStatistics(A))\n",
    "    print(getShapeType(A))\n",
    "\n",
    "    return np.dot(A, c)\n",
    "\n",
    "ourmazdas = np.array([[2018, 2012, 2010]]).T\n",
    "\n",
    "predict(ourmazdas, 0, c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72611f85",
   "metadata": {},
   "source": [
    "But how good is our regression model? In order to assess this, we would need some *held-out test data with labels*. And then we would calculate how well the regression predictions matched the true prices for the held-out data. In particular, we would calculate $$R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y})^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2}$$\n",
    "The numerator there tells us the error of the model (vs just calculating the mean of the data) and the denominator tells us the error of the data vs the mean of the data.\n",
    "\n",
    "In fact, the numerator is the residuals! So we can rewrite this as $$R^2 = 1 - \\frac{r_i^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2}$$\n",
    "\n",
    "Okay, so first let's split our data into *train* and *test*. \n",
    "\n",
    "This is actually a little tricky because we know car prices change over time. But we don't know when these ads were posted. So we'll assume they were all posted at about the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280308e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = np.split(data, [int(len(data) / 10 * 8)])\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253dab6",
   "metadata": {},
   "source": [
    "Then, let's use the *train* data to fit the model, and the *test* data to evaluate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, res = fit(train, 1, 0)\n",
    "# this is b and m!\n",
    "print(c, res)\n",
    "plotxyyhat(train[:, 1], train[:, 0], c[1], c[0])\n",
    "\n",
    "yhat = predict(test, 1, c)\n",
    "plotxyyhat(test[:, 1], test[:, 0], c[1], c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec395a9",
   "metadata": {},
   "source": [
    "Now that's interesting. The *fit* on the test data does not appear to be as good as the *fit* on the training data. Hmm...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume these are numpy arrays\n",
    "def rsquared(y, yhat):\n",
    "    if len(y) != len(yhat):\n",
    "        print(\"Need y and yhat to be the same length!\")\n",
    "        return 0\n",
    "    return 1 - (((y - yhat)**2).sum() / ((y - y.mean())**2).sum())\n",
    "\n",
    "yhat = predict(train, 1, c)\n",
    "print(rsquared(train[:, 0], yhat))\n",
    "yhat = predict(test, 1, c)\n",
    "print(rsquared(test[:, 0], yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f74fa",
   "metadata": {},
   "source": [
    "How does $R^2$ resemble $MSSE$, and how not? What does $R^2$ look like when the dependent variable is very highly correlated with the independent variable, for example they are the same? What does it look like when they are not at all correlated?\n",
    "\n",
    "Let's come back to this notion of *correlation*. If two variables are highly *correlated* then a linear regression calculated using one of them as the independent variable and the other as the dependent variable will have *what size of* $R^2$? \n",
    "\n",
    "If two variables are highly correlated does this mean one *caused* the other? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741074c",
   "metadata": {},
   "source": [
    " ## Multiple Linear Regression\n",
    " \n",
    " I want to predict price as a function of age and mileage. After all, an old car with low mileage may be worth more than a new car with high mileage. Actually, I probably want to include some of those other variables (features) too! (Which ones?)\n",
    " \n",
    "It turns out I can do this using multiple linear regression. The function I will want to fit will be:\n",
    "$$ F(x_{1i}, x_{2i},...,x_{Mi}) = c_0 + c_1x_{1i} + c_2x_{2i} + ... + c_Mx_{Mi} $$\n",
    "and I do this by minimizing the sum of the squares of the residuals $r_i = y_i-F(x_{1i}, x_{2i},..., x_{Mi})$.\n",
    "\n",
    "In terms of matrix math, for $N$ data points $A$ will just be a matrix of shape $(N, M+1)$ (including the leading column of 1s) and $\\vec{c}$ will have shape $(M+1, 1)$ (including $c_0$, the intercept) and $\\vec{y}$ will have shape $(N, 1)$ (as before).\n",
    "\n",
    "Let's do it! Then, next time we meet let's look at the math behind it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: we'll want to adjust fit and predict to take a range of columns from the input data, like: data[np.ix_(np.arange(data.shape[0]), [1,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data, independent, dependent):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[np.ix_(np.arange(data.shape[0]), independent)]\n",
    "    print(getSummaryStatistics(x))\n",
    "    print(getShapeType(x))\n",
    "\n",
    "    # We add a column of 1s for the intercept\n",
    "    A = np.hstack((np.array([np.ones(x.shape[0])]).T, x))\n",
    "    print(getSummaryStatistics(A))\n",
    "    print(getShapeType(A))\n",
    "\n",
    "    # This is the dependent variable \n",
    "    y = data[:, dependent]\n",
    "    print(getSummaryStatistics(y))\n",
    "    print(getShapeType(y))\n",
    "\n",
    "    # This is the regression coefficients that were fit, plus some other results\n",
    "    # c, res, _, _ = sp.linalg.lstsq(A, y)\n",
    "    c = solve_normal_equation(A, y)\n",
    "    return c\n",
    "\n",
    "def predict(data, independent, c):\n",
    "    # These are our independent variable(s)\n",
    "    x = data[np.ix_(np.arange(data.shape[0]), independent)]\n",
    "    print(getSummaryStatistics(x))\n",
    "    print(getShapeType(x))\n",
    "\n",
    "    # We add a column of 1s for the intercept\n",
    "    A = np.hstack((np.array([np.ones(x.shape[0])]).T, x))\n",
    "    print(getSummaryStatistics(A))\n",
    "    print(getShapeType(A))\n",
    "\n",
    "    return np.dot(A, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, res = fit(data, [1,2,3,5,6,7], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(data, [1,2,3,5,6,7], c)\n",
    "rsquared(data[:, 0], yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and for Amanda's Mazda:\n",
    "mymazda = np.array([[0, 2018, 3, 40000, 1, 1, 1, 7]])\n",
    "print(mymazda.shape)\n",
    "predict(mymazda, [1,2,3,5,6,7], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_normal_equation(A, y):\n",
    "    inv = sp.linalg.inv(np.dot(A.T, A))\n",
    "    part2 = np.dot(A.T, y)\n",
    "    return np.dot(inv, part2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
