{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef44267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be56e471",
   "metadata": {},
   "source": [
    "# PCA with images\n",
    "\n",
    "## PCA Review\n",
    "\n",
    "1. What does \"PCA\" stand for?\n",
    "2. What does PCA *do*?\n",
    "3. In what circumstances might you use PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15538762",
   "metadata": {},
   "source": [
    "Today's notebook is a modification of https://charlesreid1.github.io/circe/Digit%20Classification%20-%20PCA.html\n",
    "\n",
    "## Handwritten Digits Data Set\n",
    "\n",
    "The data set we wil be analyzing is a well known data set for handwriting recognition from https://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits.\n",
    "\n",
    "__Take a look at the data__.\n",
    "\n",
    "*The independent variables*: each data point (observation) is an 8 pixel by 8 pixel grayscale image. We flatten this so each data point is represented by a 64 floating point one dimensional array. \n",
    "\n",
    "*The dependent variable*: the label is the number in the image, 0 ... 9.\n",
    "\n",
    "*Reason for using PCA*: if we can project from 64 dimensions down to some number less than 10, we can fit a regression (or other!) model more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc205d",
   "metadata": {},
   "source": [
    "### Load and separate and examine the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(np.genfromtxt('data/optdigits/optdigits.tra', delimiter=',', dtype=int))  \n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split off the labels\n",
    "def split(data, ycol):\n",
    "    y = data[:, ycol]\n",
    "    xfirst = data[:, 0:ycol]\n",
    "    xsecond = data[:, ycol+1:data.shape[1]]\n",
    "    return (np.hstack((xfirst, xsecond)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b689bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y) = split(train, train.shape[1]-1)\n",
    "print(y.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some of the observations\n",
    "for index in range(10):\n",
    "    for i in range(len(x[index])):\n",
    "        if x[index][i] != 0:\n",
    "            if x[index][i] < 4:\n",
    "                x[index][i] = 0\n",
    "            else:\n",
    "                x[index][i] = 2\n",
    "    observation = x[index].reshape(8, 8)\n",
    "    plt.imshow(observation, cmap='gray_r', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6548f32",
   "metadata": {},
   "source": [
    "## PCA steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ae28860",
   "metadata": {},
   "source": [
    "### (If appropriate) normalize the variables to be in the range 0-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e17305e",
   "metadata": {},
   "source": [
    "### Center the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5516c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_train = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e960e435",
   "metadata": {},
   "source": [
    "### Compute the covariance matrix\n",
    "\n",
    "We will also visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = \n",
    "\n",
    "# Let's look at the covariance matrix\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "sns.heatmap(pd.DataFrame(covariance_matrix), annot=False, cmap='PuOr')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a6cabca",
   "metadata": {},
   "source": [
    "### Compute the eigenvectors and eigenvalues; Get an ordering over the eigenvalues; Sort the eigenvalues and eigenvectors accordingly\n",
    "\n",
    "We will also visualize the eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals, evectors = \n",
    "\n",
    "order = \n",
    "\n",
    "eigenvals_sorted = evals[order]\n",
    "eigenvecs_sorted = evectors[:, order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the eigenvectors, sorted by eigenvalue rank, and visually identify which eigenvector components dominate in each eigenvalue. This is essentially a visualization of what information the principal component analysis has judged most important.\n",
    "fig = plt.figure(figsize=(14,3))\n",
    "sns.heatmap(pd.DataFrame(eigenvecs_sorted[:, 0:21].T), \n",
    "            annot=False, cmap='coolwarm',\n",
    "           vmin=-0.5,vmax=0.5)\n",
    "\n",
    "plt.ylabel(\"Ranked Eigenvalue\")\n",
    "plt.xlabel(\"Eigenvector Components\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f200e0c",
   "metadata": {},
   "source": [
    "### Compute the proportional variance accounted for by each principal component; Compute the cumulative sum of the proportional variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = np.sum(eigenvals_sorted)\n",
    "proportional_variances = np.array([eigenvalue / sum for eigenvalue in eigenvals_sorted])\n",
    "cumulative_sum = np.cumsum(proportional_variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe6631",
   "metadata": {},
   "source": [
    "### Scree and Elbow plots\n",
    "\n",
    "These are two plots that will help you move beyond \"just keep the eigenvalues that account for 90% of the variance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the proportional variance\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.bar(range(len(proportional_variances)), proportional_variances, alpha=0.5, align='center',\n",
    "        label='Proportional variance')\n",
    "\n",
    "plt.ylabel('Proportional variance ratio')\n",
    "plt.xlabel('Ranked Principal Components')\n",
    "plt.title(\"Scree Graph\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(cumulative_sum)\n",
    "\n",
    "ax1.set_ylim([0,1.0])\n",
    "\n",
    "ax1.set_xlabel('Number of Principal Components')\n",
    "ax1.set_ylabel('Cumulative explained variance')\n",
    "ax1.set_title('Elbow Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a2e2e87",
   "metadata": {},
   "source": [
    "*Looking at this elbow plot, how many principal components do you think we want to keep?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18768882",
   "metadata": {},
   "source": [
    "### Examine the principal components and select some of them; Project the data into PCA space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = eigenvecs_sorted[:, :10]\n",
    "projected = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "162f28bb",
   "metadata": {},
   "source": [
    "### You can also reconstruct the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a83af",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* https://www.displayr.com/8-tips-for-interpreting-r-squared/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
