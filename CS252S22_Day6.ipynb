{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efd2c21",
   "metadata": {},
   "source": [
    "Data manipulations\n",
    "---------------------------------------\n",
    "\n",
    "A matrix transformation is a matrix multiplication between a transformation matrix M and a data matrix D that gives you a manipulated data matrix D' as output.\n",
    "\n",
    "We can use matrix multiplications to transform our data (our data points, represented as feature vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956d96c",
   "metadata": {},
   "source": [
    "Let's load and plot the data.\n",
    "This data comes from https://www.kaggle.com/tolgahancepel/toyota-corolla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "data = np.array(np.genfromtxt('data/ToyotaCorolla.csv', delimiter=',', converters={3: lambda x: 1 if x == 'Diesel' else 0}, skip_header=1, dtype=int, encoding=None))  \n",
    "\n",
    "# getting a pandas dataframe so I can visualize the data\n",
    "df = pd.DataFrame(data, columns=[\"price\", \"age\", \"km\", \"fueltype\", \"hp\", \"metcolor\", \"automatic\", \"cc\", \"doors\", \"weight\"])\n",
    "\n",
    "# a parallel coordinates plot is useful for figuring out if any variables are more predictive of the dependent variable (price) than any others\n",
    "pd.plotting.parallel_coordinates(df, \"price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f57d34",
   "metadata": {},
   "source": [
    "I can't see my data!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't decide if doors or automatic are more important; how might I decide?\n",
    "sns.scatterplot(x=\"km\", y=\"price\", size=\"age\", hue =\"automatic\", palette=\"colorblind\", sizes=(40, 200) , alpha=.6, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b41687",
   "metadata": {},
   "source": [
    "I still can't see my data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, y_vars = [\"price\"], x_vars = [\"age\", \"km\", \"fueltype\", \"hp\", \"metcolor\", \"automatic\", \"cc\", \"doors\", \"weight\"], kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcc09d",
   "metadata": {},
   "source": [
    "Let's get some **summary statistics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f062c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    return np.array([data.max(axis=0), data.min(axis=0), data.mean(axis=0, dtype=int)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319be1a1",
   "metadata": {},
   "source": [
    "Let's **reduce the data** to two dimensions, just price and age, since age looks like the one with the clearest correlation with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are we going to get just those two columns?\n",
    "reducedData = data[:, :2]\n",
    "\n",
    "# What if we just wanted price and km?\n",
    "reducedDataSkipCol = data[np.ix_(np.arange(data.shape[0]), [0, 2])]\n",
    "\n",
    "print(getSummaryStatistics(reducedDataSkipCol))\n",
    "print(getShapeType(reducedDataSkipCol))\n",
    "\n",
    "# You can do projection (down or up) also by matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8ef9f",
   "metadata": {},
   "source": [
    "We need to add a dummy column of ones so we can do the matrix multiplications for these transformations. Why? See https://www.sciencedirect.com/topics/mathematics/homogeneous-coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we append a whole column?\n",
    "homogenizedData = np.append(reducedData, np.array([np.ones(reducedData.shape[0], dtype=int)]).T, axis=1)\n",
    "print(\"homogenized data\")\n",
    "print(getSummaryStatistics(homogenizedData))\n",
    "print(getShapeType(homogenizedData))\n",
    "\n",
    "def plot2d(data):\n",
    "    sns.scatterplot(x=\"age\", y=\"price\", palette=\"colorblind\", sizes=(40, 200) , alpha=.6, data=pd.DataFrame(data, columns=[\"price\", \"age\", \"\"]))\n",
    "    \n",
    "plot2d(homogenizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2c455",
   "metadata": {},
   "source": [
    "Let's **translate** that price column so that it too starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to define a transformation matrix that will allow us to shift the price variable; this one will be the identity matrix with the translation specified in an extra last column\n",
    "translateTransform = np.eye(3, 3, dtype=int)\n",
    "translateTransform[0, 2] = -reducedData[:, 0].min()\n",
    "print(\"transformMatrix\")\n",
    "print(getShapeType(translateTransform))\n",
    "print(translateTransform)\n",
    "\n",
    "# now we need to do the translation\n",
    "translatePriceData = (translateTransform@homogenizedData.T).T\n",
    "print(\"after translation, translatePriceData\")\n",
    "print(getSummaryStatistics(translatePriceData))\n",
    "print(getShapeType(translatePriceData))\n",
    "plot2d(translatePriceData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb38fcc8",
   "metadata": {},
   "source": [
    "Let's **scale** that age column so it's months instead of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63221e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleTransform = np.eye(3, 3, dtype=int)\n",
    "scaleTransform[1, 1] = 12\n",
    "print(\"transformMatrix\")\n",
    "print(getShapeType(scaleTransform))\n",
    "print(scaleTransform)\n",
    "\n",
    "scaleAgeData = (scaleTransform@translatePriceData.T).T\n",
    "print(\"after scaling, scaleAgeData\")\n",
    "print(getSummaryStatistics(scaleAgeData))\n",
    "print(getShapeType(scaleAgeData))\n",
    "plot2d(scaleAgeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737e93b",
   "metadata": {},
   "source": [
    "Let's try **global (max-min) normalization**\n",
    "\n",
    "Okay, so here is how that works:\n",
    "1. subtract the global minimum from each datapoint\n",
    "2. divide by the global range (max - min)\n",
    "\n",
    "What is the effect on the data?\n",
    "\n",
    "What does that look like from the perspective of operations we have learned so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c811513",
   "metadata": {},
   "outputs": [],
   "source": [
    "translateTransform = np.eye(3, 3, dtype=int)\n",
    "translateTransform[:, 2] = -reducedData.min()\n",
    "print(\"transformMatrix\")\n",
    "print(translateTransform)\n",
    "\n",
    "scaleTransform = np.eye(3, 3)\n",
    "scaleTransform[0, 0] = 1 / (reducedData.max() - reducedData.min())\n",
    "scaleTransform[1, 1] = 1 / (reducedData.max() - reducedData.min())\n",
    "scaleTransform[2, 2] = 1 / (reducedData.max() - reducedData.min())\n",
    "print(\"transformMatrix\")\n",
    "print(getShapeType(scaleTransform))\n",
    "print(scaleTransform)\n",
    "\n",
    "totalTransform = scaleTransform@translateTransform\n",
    "print(\"transformMatrix\")\n",
    "print(getShapeType(totalTransform))\n",
    "print(totalTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalNormalizedData = (totalTransform@homogenizedData.T).T\n",
    "print(\"after global normalization, globalNormalizedData\")\n",
    "print(getSummaryStatistics(globalNormalizedData))\n",
    "print(getShapeType(globalNormalizedData))\n",
    "plot2d(globalNormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b72cb",
   "metadata": {},
   "source": [
    "I'm not sure global max-min normalization makes sense for data like this. Instead, let's try **max-min normalization per variable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b538123",
   "metadata": {},
   "outputs": [],
   "source": [
    "translateTransform = np.eye(homogenizedData.shape[1], dtype=int)\n",
    "translateTransform[:, 2] = np.array([-homogenizedData[:, 0].min(), -homogenizedData[:, 1].min(), 1], dtype=int)\n",
    "print(translateTransform)\n",
    "scaleTransform = np.eye(homogenizedData.shape[1]) * [1 / (homogenizedData[:, 0].max() - homogenizedData[:, 0].min()), 1 / (homogenizedData[:, 1].max() - homogenizedData[:, 1].min()), 1]\n",
    "\n",
    "print(\"transformMatrix\")\n",
    "print(getShapeType(translateTransform @ scaleTransform))\n",
    "print(translateTransform @ scaleTransform)\n",
    "\n",
    "\n",
    "localNormalizedData = (translateTransform @ scaleTransform @homogenizedData.T).T\n",
    "print(\"after per variable normalization, localNormalizedData\")\n",
    "print(getSummaryStatistics(localNormalizedData))\n",
    "print(getShapeType(localNormalizedData))\n",
    "plot2d(localNormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad3b1f",
   "metadata": {},
   "source": [
    "Max-min normalization will move everything to the unit square, but that may not help me see things more clearly. What if I try **z-scoring**: normalizing each feature by its mean and standard deviation instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2370c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "localNormalizedData = \n",
    "print(\"after per variable normalization, localNormalizedData\")\n",
    "print(getSummaryStatistics(localNormalizedData))\n",
    "print(getShapeType(localNormalizedData))\n",
    "plot2d(localNormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4928bbd",
   "metadata": {},
   "source": [
    "Let's **rotate** the data by 270 degrees, because I like things to go up to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotateTransform = \n",
    "print(\"transformMatrix\")\n",
    "print(getShapeType(rotateTransform))\n",
    "print(rotateTransform)\n",
    "\n",
    "rotatedData = \n",
    "print(\"after rotating, rotatedData\")\n",
    "print(getSummaryStatistics(rotatedData))\n",
    "print(getShapeType(rotatedData))\n",
    "sns.scatterplot(x=\"km\", y=\"price\", palette=\"colorblind\", sizes=(40, 200) , alpha=.6, data=pd.DataFrame(rotatedData, columns=[\"price\", \"km\", \"\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b122e9",
   "metadata": {},
   "source": [
    "What if I wanted to rotate it *and translate it to be centered on zero*?\n",
    "\n",
    "Some resources:\n",
    "* https://staff.fnwi.uva.nl/r.vandenboomgaard/IPCV20162017/LectureNotes/MATH/homogenous.html\n",
    "* https://primer-computational-mathematics.github.io/book/d_geosciences/remote_sensing/Image_Transformations_and_Orthorectification.html\n",
    "* https://www.informit.com/articles/article.aspx?p=2854376&seqNum=8\n",
    "* https://towardsdatascience.com/normalization-techniques-in-python-using-numpy-b998aa81d754\n",
    "* https://www.machinecurve.com/index.php/2020/11/19/how-to-normalize-or-standardize-a-dataset-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
