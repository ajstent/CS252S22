{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1834e96",
   "metadata": {},
   "source": [
    "# About the Python\n",
    "\n",
    "Remember our core python package for this course:\n",
    "* numpy - great for processing vectors, matrices and tensors, which are the foundational data types for data analysis, visualization and machine learning\n",
    "\n",
    "And don't forget our go-tos for visualization:\n",
    "* matplotlib\n",
    "* seaborn\n",
    "\n",
    "Both of these operate over pandas dataframes, and we can make a pandas dataframe from a numpy array easily.\n",
    "\n",
    "Today we'll learn about another python package:\n",
    "* scipy - great for scientific computing (linear algebra, differential equations and more!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243b190",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The first three steps in data science are to:\n",
    "* find your data\n",
    "* look at your data\n",
    "* clean your data\n",
    "\n",
    "Today we will be working with a set of Craigslist listings for used Mazda 3s. (!!)\n",
    "\n",
    "This dataset is the Mazda 3 subset from https://www.kaggle.com/austinreese/craigslist-carstrucks-data after some cleanup (basically, I selected all the variants of Mazda 3 in the model column, and then removed some columns).\n",
    "\n",
    "Take a look at it in data/mazdas.csv!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3775ce",
   "metadata": {},
   "source": [
    "Now we will load this dataset. I'm going to load it the unpleasant way (rather than using the Data class), because I want to use those nonnumeric colums. \n",
    "\n",
    "Because our numpy arrays all have to be the same type, we first need to:\n",
    "* figure out which columns we want\n",
    "* define some converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just does pattern matching\n",
    "import re\n",
    "\n",
    "def conditionConverter(x):\n",
    "    values = ['', 'new', 'like new', 'excellent', 'good', 'fair', 'salvage']\n",
    "    return values.index(x)\n",
    "\n",
    "def titleConverter(x):\n",
    "    values = ['', 'clean', 'lien', 'rebuilt','salvage']\n",
    "    return values.index(x)\n",
    "\n",
    "def transmissionConverter(x):\n",
    "    values = ['', 'automatic', 'manual', 'other']\n",
    "    return values.index(x)\n",
    "\n",
    "def typeConverter(x):\n",
    "    if re.match(r'(sedan|coupe)', x):\n",
    "        return 1\n",
    "    elif re.match(r'(mini-van|hatchback|wagon|SUV)', x):\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "def colorConverter(x):\n",
    "    values = ['', 'grey', 'white', 'black', 'blue', 'orange', 'purple', 'red', 'green', 'brown', 'custom', 'silver']\n",
    "    if x in values:\n",
    "        return values.index(x)\n",
    "    else:\n",
    "        print(\"couldn't find |\" + x + \"|\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca359103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# This dataset is the mazda subsample from https://www.kaggle.com/austinreese/craigslist-carstrucks-data after some cleanup\n",
    "\n",
    "columns = [\"price\", \"age\", \"condition\", \"odometer\", \"title_type\", \"transmission\", \"type\", \"color\"]\n",
    "data = np.array(np.genfromtxt('data/mazdas.csv', delimiter=',', usecols=(1,2,5,6,7,8,9,10), converters={5: conditionConverter, 7: titleConverter, 8: transmissionConverter, 9: typeConverter, 10: colorConverter}, skip_header=2, dtype=int, encoding='utf-8'))  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5a5ca",
   "metadata": {},
   "source": [
    "*If we loaded it using your Data class from project one, what columns could we access?*\n",
    "\n",
    "Let's do a pairplot so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ceb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=columns)\n",
    "seaborn.pairplot(df, y_vars = columns[0], x_vars = columns[1:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef809d3",
   "metadata": {},
   "source": [
    "*What do we notice?*\n",
    "\n",
    "Let's get some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    return np.array([data.max(axis=0), data.min(axis=0), data.mean(axis=0, dtype=int)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc62d6b",
   "metadata": {},
   "source": [
    "Let's add a new summary statistic. This one will tell us how highly *correlated* two variables are. If two variables are highly correlated, then you can estimate one using the other. For example:\n",
    "* price and price should be exactly the same (correlation of 1) \n",
    "* while price and -price should have a correlation of -1, and\n",
    "* price and random numbers should have correlation of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ac409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(data[:, 0], data[:, 0], rowvar=True)[0,1])\n",
    "print(np.corrcoef(data[:, 0], -data[:, 0], rowvar=True)[0,1])\n",
    "print(np.corrcoef(data[:, 0], np.random.randint(0, data[:, 0].max(), len(data[:, 0])), rowvar=True)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4bdf4d",
   "metadata": {},
   "source": [
    "Okay, what are the correlations for the variables in the mazda3 dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(columns)):\n",
    "    print(columns[i], np.corrcoef(data[:, 0], data[:, i], rowvar=True)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16134d82",
   "metadata": {},
   "source": [
    "*What do we notice?*\n",
    "\n",
    "# Regression\n",
    "\n",
    "Today we are moving on from:\n",
    "* data loading\n",
    "* data visualization\n",
    "* basic data analysis\n",
    "  * summary statistics on data\n",
    "  * data transformation and normalization\n",
    "\n",
    "to more advanced data analysis, in particular *regression*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b850ff",
   "metadata": {},
   "source": [
    "## What is regression? \n",
    "\n",
    "Regression allows us to:\n",
    "* determine the *nature* of a relationship between one (or more!) independent variables and a dependent variable\n",
    "* determine the *strength* of the relationship\n",
    "\n",
    "Regression *fits* a function to a dataset.\n",
    "\n",
    "Regression is *not* the same as interpolation: we don't want to fit so closely that we exactly pass through each data point, but rather fit so that we generalize over the data. Why is this?\n",
    "* because the data sets we have are not *all* the data, but a *sample* of the data, and other samples may be somewhat different\n",
    "* because we want to be able to *explain* relationships between variables\n",
    "\n",
    "Both of these require some generalization/abstraction away from the actual data.\n",
    "\n",
    "Okay, so we need some functions; we need a method for making the function \"fit\" the data; and we need a measure of how \"good\" the fit is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac8405",
   "metadata": {},
   "source": [
    "## What kinds of functions can we fit? \n",
    "\n",
    "Any kind! What are some kinds of [function](https://www.wolframalpha.com/input?i=mathematical+function)?\n",
    "\n",
    "Why might we prefer simpler functions over more complex ones?\n",
    "\n",
    "We are going to start with *linear regression*. What type of function do we fit when we do linear regression? A linear function! You might see it written like $$F(x_i) = b + mx_i$$ or like $$\\hat{y}_i = b+ mx_i$$It's called linear because when you plot it you get a line that crosses 0 at $b$ (the \"intercept\") and has slope $m$.\n",
    "\n",
    "Note that this function tries to calculate one variable ($y$) as a function of one other variable ($x$). Next week, we will look at functions that calculate $y$ as a function of multiple other variables.\n",
    "\n",
    "For the mazda3 dataset, which one variable do you think would be the best one to use to calculate or approximate price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f44154",
   "metadata": {},
   "source": [
    "## What does it mean to *fit* a function? \n",
    "\n",
    "Now let's talk about methods for making the function \"fit\" the data. We know $x$, and we know $y$. We do *not* know the values for $b$ or $m$; that's what we need to figure out. We could try a random or educated guess :). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotxyyhat(x, y, m, b):\n",
    "    plt.plot(x, y, 'o', label='data')\n",
    "    yhat = m*x + b\n",
    "    plt.plot(x, yhat, label='least squares fit, $y = mx + b$')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(framealpha=1, shadow=True)\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "m = 10\n",
    "b = -2000\n",
    "\n",
    "plotxyyhat(data[:, 1], data[:, 0], m, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df7d93",
   "metadata": {},
   "source": [
    "Can we do better than that?\n",
    "\n",
    "Yes, but we need a notion of \"good\" to assess \"better\". \n",
    "\n",
    "## How do we measure how \"good\" the fit is?\n",
    "\n",
    "If we have a function and a set of data points, how well does the function fit the data? \n",
    "\n",
    "The \"bit left over\" or the \"distance\", which we call the *residual*, is often calculated as: $$r_i = y_i - F(x_i)$$ (or, $r_i = y_i - \\hat{y}_i$).\n",
    "\n",
    "And how can we combine these differences? We could:\n",
    "* Take the average, median, min or max of the distances\n",
    "* Take the average, median, min or max of the absolute distances\n",
    "* Take the sum of the absolute distances\n",
    "* Take the mean of the sum of the square of the distances (MSSE, or *mean sum of squared error*):\n",
    "$$MSSE = 1 / N \\sum_{i=1}^N (r_i)^2 = 1/N \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msse(x, y, m, b):\n",
    "    if len(x) != len(y):\n",
    "        print(\"Need x and y to be the same length!\")\n",
    "        return 0\n",
    "    yhat = [m*xi + b for xi in x]\n",
    "    r = 0.0\n",
    "    for i in range(len(x)):\n",
    "        r += (float(y[i]) - float(yhat[i]))*(float(y[i]) - float(yhat[i]))\n",
    "    r = (1 / len(x)) * r\n",
    "    return r\n",
    "\n",
    "print(msse(data[:, 1], data[:, 0], m, b))\n",
    "\n",
    "# what happens if our slope is 0 and our intercept is the mean value for price?\n",
    "print(msse(data[:, 1], data[:, 0], 0, data[:, 0].mean()))\n",
    "# let's see if we can do better than just using the mean..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9278a",
   "metadata": {},
   "source": [
    "Okay, so to calculate $m$ and $b$, we need to _minimize_ $MSSE$ with respect to each. We do this using a method called [least squares](https://en.wikipedia.org/wiki/Least_squares) (see also [least squares](https://www.wolframalpha.com/input?i=least+squares). We take the partial derivatives of $MSSE$ with respect to $m$ and $b$, setting to 0 (the minimum) and solving (*please check my math!*):\n",
    "* partial derivative of $MSSE$ ($p$) with respect to $m$: $$\\frac{\\partial p}{\\partial m} = 0 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial m} (y_i - F(x_i))^2 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial m} (y_i - (m x_i + b))^2 = \\sum_{i=1}^N -2 x_i (y_i - (m x_i + b)) = \\sum_{i=1}^N x_i y_i -m \\sum_{i=1}^N {x_i}^2 - b \\sum_{i=1}^N x_i$$\n",
    "* partial derivative of $MSSE$ ($p$) with respect to $b$: $$\\frac{\\partial p}{\\partial b} = 0 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial b} (y_i - F(x_i))^2 = 1/N \\sum_{i=1}^N \\frac{\\partial }{\\partial b} (y_i - (m x_i + b))^2 = \\sum_{i=1}^N -2 (y_i - (m x_i + b)) = \\sum_{i=1}^N y_i - m \\sum_{i=1}^N x_i  - b N$$\n",
    "\n",
    "So then, \n",
    "$$ m = \\frac{\\sum_{i=1}^N x_i \\sum_{i=1}^N y_i - N \\sum_{i=1}^N x_i y_i}{(\\sum_{i=1}^N x_i)^2 - N \\sum_{i=1}^N {x_i}^2}$$\n",
    "$$ b = \\frac{\\sum_{i=1}^N x_i \\sum_{i=1}^N x_i y_i -\\sum_{i=1}^N {x_i}^2 \\sum_{i=1}^N y_i}{{(\\sum_{i=1}^N x_i})^2 - N\\sum_{i=1}^N {x_i}^2}$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^N {x_i}^2 & \\sum_{i=1}^N x_i \\\\\n",
    "\\sum_{i=1}^N x_i & N\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "m \\\\\n",
    "b\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=1}^N x_i y_i \\\\\n",
    "\\sum_{i=1}^N y_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now this is something we can calculate using matrix math:\n",
    "$$F(x_i) = b + m x_i = (1, X_i) \\cdot (b, m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cca9b",
   "metadata": {},
   "source": [
    "The function \"lstsq\" in the scipy package's linalg (linear algebra) subpackage\n",
    "fits a linear regression using least squares. It gives us predicted $y$ values $\\hat{y}$ and residuals for each $\\hat{y}$. Let's try it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8893fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# These are our independent variable(s)\n",
    "x = data[:, 1]\n",
    "print(getSummaryStatistics(x))\n",
    "print(getShapeType(x))\n",
    "\n",
    "# We add a column of 1s for the intercept\n",
    "M = x[:, np.newaxis]**[0, 1]\n",
    "print(getSummaryStatistics(M))\n",
    "print(getShapeType(M))\n",
    "\n",
    "# This is the dependent variable \n",
    "y = data[:, 0]\n",
    "print(getSummaryStatistics(y))\n",
    "print(getShapeType(y))\n",
    "\n",
    "# This is the regression coefficients that were fit, plus some other results\n",
    "p, res, _, _ = sp.linalg.lstsq(M, y)\n",
    "\n",
    "# this is b and m!\n",
    "print(p)\n",
    "\n",
    "plotxyyhat(data[:, 1], data[:, 0], p[1], p[0])\n",
    "print(msse(data[:, 1], data[:, 0], p[1], p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b904a",
   "metadata": {},
   "source": [
    "## And, this is a function we can use to predict the $y$ (calculate the $\\hat{y}$) for new $x$s, so it's a *model*!\n",
    "\n",
    "For example, my car was a 2018 Mazda 3, so what should its Craigslist price be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p[1]*2018+p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55025d54",
   "metadata": {},
   "source": [
    "*What about your Mazda 3s??*\n",
    "\n",
    "Of course, this model is based on *historical* car prices, and what has happened over the past year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
