{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1cf4b2",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0df6e547",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Regression allows us to:\n",
    "* determine the *nature* of a relationship between one (or more!) independent variables and a dependent variable\n",
    "* determine the *strength* of the relationship\n",
    "\n",
    "Regression *fits* a function to a dataset.\n",
    "\n",
    "**Regression is *not* the same as interpolation**: we don't want to fit so closely that we exactly pass through each data point, but rather fit so that we generalize over the data. Why is this?\n",
    "* because the data sets we have are not *all* the data, but a *sample* of the data, and other samples may be somewhat different\n",
    "* because we want to be able to *explain* relationships between variables\n",
    "\n",
    "Both of these require some generalization/abstraction away from the actual data.\n",
    "\n",
    "Okay, so we need three things:\n",
    "1. a function\n",
    "2. a method for making the function \"fit\" the data\n",
    "3. a measure of how \"good\" the fit is"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb149e5c",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "There are lots of types of regression. Today we will look at the most basic: linear regression.\n",
    "\n",
    "For linear regression, the function we fit looks like:\n",
    "\n",
    "$\\hat{y_i} = b + m x_i$\n",
    "\n",
    "The $m$ is the *slope* (or a *weight* for $x_i$).\n",
    "\n",
    "The $b$ is the *bias* (offset, intercept). It says where the function will cross the y axis.\n",
    "\n",
    "The $x_i$ is the value of the *independent variable* (feature) for the $i$ th data point.\n",
    "\n",
    "The $\\hat{y_i}$ we want to be as close as possible to $y_i$, the value of the *dependent variable* (label) for the $i$ th data point. For linear regression, $y_i$ s should be quantitative.\n",
    "\n",
    "Notice  that this function tries to calculate one variable ($y_i$) as a function of one other variable ($x_i$). Next week, we will look at functions that calculate $y_i$ as a function of multiple other variables.\n",
    "\n",
    "**Question**: What type of function is this? Does it fit:\n",
    "* An upside down U shape curve?\n",
    "* A line?\n",
    "* An S shape curve?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6f44154",
   "metadata": {},
   "source": [
    "## What does it mean to *fit* a function? \n",
    "\n",
    "Now let's talk about methods for making the function \"fit\" the data. We know $x_i$, and we know $y_i$. We do *not* know the values for $b$ or $m$; that's what we need to figure out. In order to do that, we need a notion of \"goodness of fit\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38df7d93",
   "metadata": {},
   "source": [
    "## How do we measure how \"good\" the fit is?\n",
    "\n",
    "If we have a function and a set of data points, how well does the function fit the data? \n",
    "\n",
    "The \"bit left over\" or the \"distance\", which we call the *residual*, is often calculated as: $r_i = y_i - \\hat{y_i}$. Look at the picture: if the diagonal line is the function we fit to the data, the length of each vertical line is a residual.\n",
    "\n",
    "<img src=\"https://i0.wp.com/statisticsbyjim.com/wp-content/uploads/2017/04/residuals.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "*Image from https://statisticsbyjim.com/regression/mean-squared-error-mse/*\n",
    "\n",
    "And how can we combine these residuals? We could:\n",
    "* Take the average, median, min or max of the distances\n",
    "* Take the average, median, min or max of the absolute distances\n",
    "* Take the sum of the absolute distances\n",
    "\n",
    "**Question**: What is not great about each of these?\n",
    "* Think about data points that fall *above* or *below* the line we fit.\n",
    "* Think about small and large data sets.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30c291b0",
   "metadata": {},
   "source": [
    "What we will do is take the mean of the sum of the square of the distances (MSSE, or *mean sum of squared error*):\n",
    "\n",
    "$MSSE = 1 / N \\sum_{i=1}^N (r_i)^2 = 1/N \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "What is good about this measure of goodness of fit?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25d7b781",
   "metadata": {},
   "source": [
    "## Now in python\n",
    "\n",
    "Let's load and look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc074ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For today we only care about price and year\n",
    "data = np.array(np.genfromtxt('data/vehiclesNumeric.csv', delimiter=',', skip_header=1, dtype=int, encoding=\"utf-8\", usecols=[1,2]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436978be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStatistics(data):\n",
    "    print(\"min, max, mean, std per variable\")\n",
    "    return pd.DataFrame([data.min(axis=0), data.max(axis=0), data.mean(axis=0), data.std(axis=0)])\n",
    "\n",
    "def getShapeType(data):\n",
    "    print(\"shape\")\n",
    "    return (data.shape, data.dtype)\n",
    "\n",
    "print(getSummaryStatistics(data))\n",
    "print(getShapeType(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba4d912b",
   "metadata": {},
   "source": [
    "We don't need to transform this data, since we only have one independent variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a01395d5",
   "metadata": {},
   "source": [
    "**Team exercise**: in your teams, implement linear_regression and msse. Assume that $x$, $y$ and $\\hat{y}$ are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, m, b):\n",
    "    return x*m + b\n",
    "\n",
    "def msse(y, yhat):\n",
    "    r = (np.square(y - yhat)).mean()\n",
    "    return r\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7284e02",
   "metadata": {},
   "source": [
    "What happens if we set the slope to 0 and the intercept to the mean value for price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df651c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is model year\n",
    "x = data[:, 1]\n",
    "\n",
    "# y is price\n",
    "y = data[:, 0]\n",
    "\n",
    "# calculate yhat\n",
    "yhat = linear_regression(x, 0, y.mean())\n",
    "print(msse(y, yhat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3c777f1",
   "metadata": {},
   "source": [
    "Let's plot the line we fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotxyyhat(x, y, yhat):\n",
    "    plt.plot(x, y, 'o', label='data')\n",
    "    plt.plot(x, yhat, label='least squares fit, $y = mx + b$')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(framealpha=1, shadow=True)\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.show()\n",
    "\n",
    "plotxyyhat(x, y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "871d77ef",
   "metadata": {},
   "source": [
    "Can we do better than just guessing the slope and intercept?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14b9278a",
   "metadata": {},
   "source": [
    "## An analytical solution for finding $m$ and $b$\n",
    "\n",
    "Okay, so to calculate $m$ and $b$, we need to _minimize_ $MSSE$ with respect to each. We do this using a method called [least squares](https://en.wikipedia.org/wiki/Least_squares) (see also [least squares](https://www.wolframalpha.com/input?i=least+squares)). \n",
    "\n",
    "This is something we can calculate using matrix multiplication!\n",
    "\n",
    "$\\vec{y} = b + m \\vec{x} = (1, \\vec{x}) \\cdot (b, m)$. \n",
    "\n",
    "We typically write this as $\\vec{y} = A \\cdot \\vec{c}$, with $A = (1, \\vec{x})$ (a matrix with two columns where the first column is all 1s) and $\\vec{c} = (b, m)$.\n",
    "\n",
    "**Question**: Why does $\\vec{y} = A \\cdot \\vec{c}$ work?\n",
    "* Think about how matrix multiplication works.\n",
    "* Think about row 1 in $A$: it will be $(1, x_0)$. How does that combine with $(b, m)$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e68cca9b",
   "metadata": {},
   "source": [
    "The function \"lstsq\" in the scipy package's linalg (linear algebra) subpackage\n",
    "fits a linear regression using least squares. Let's try it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8893fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as sp_la\n",
    "\n",
    "def fit(x, y):\n",
    "    # We add a column of 1s for the intercept; this line: a) adds a leading column to x; b) fills it in with $x_i^0$; c) fills in the next column with $x_i^1$\n",
    "    A = x[:, np.newaxis]**[0, 1]\n",
    "\n",
    "    # This bives the regression coefficients that were fit, plus some other results\n",
    "    c, _, _, _ = sp_la.lstsq(A, y)\n",
    "\n",
    "    return c\n",
    "\n",
    "b, m = fit(x, y)\n",
    "# this is b and m!\n",
    "print(\"b \", b, \"m \", m)\n",
    "yhat = linear_regression(x, m, b)\n",
    "print(msse(y, yhat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7459880",
   "metadata": {},
   "source": [
    "Is this better than the guess we made before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotxyyhat(x, y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "803b904a",
   "metadata": {},
   "source": [
    "## And, this is a function we can use to predict the $y$ (calculate the $\\hat{y}$) for new $x$ s, so it's a *model*!\n",
    "\n",
    "For example, if my car was a 2018 model year, so what should its Craigslist price be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m*2010+b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "180c3e4c",
   "metadata": {},
   "source": [
    "*Of course, since 2021 we have learned that Hyundai and Kia are very easily stolen and their prices have dropped like a stone. But that's a story for another day!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
