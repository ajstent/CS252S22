{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c79c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilityfunctions as uf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f370b",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Clustering algorithms separate a data set into groups, or clusters, that are near each other (similar to each other) using a distance metric we choose or define.\n",
    "\n",
    "When we fit a regression model, we know the dependent variable - the label, the answer. When we cluster, we don't. Clustering is therefore an *unsupervised* method, although we as data scientists can make all kinds of decisions to influence it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e372ca",
   "metadata": {},
   "source": [
    "# K-means clustering\n",
    "\n",
    "K-means clustering is one clustering algorithm. It divides the data into $k$ clusters. Each cluster has a *centroid*, or central point (or \"mean\"). \n",
    "\n",
    "## What we want to optimize\n",
    "\n",
    "The points in the dataset are assigned to their closest centroid. In other words, we want to minimize the distances between data points and the centroids they are assigned to, across the whole data set. We want to minimize the *inertia*:\n",
    "$$inertia = 1/N \\sum_{j=1}^N d(\\vec{x_j}, \\vec{m_{\\vec{x_j}}})^2$$, where $\\vec{m_{x_j}}$ is the centroid of the cluster that $x_j$ is currently assigned to, and $d$ is your chosen distance metric.\n",
    "\n",
    "__What does this look like?__\n",
    "\n",
    "## The algorithm\n",
    "\n",
    "To make this computationally efficient, we calculate an approximate solution by iteration:\n",
    "1. Pick initial centroids.\n",
    "2. For step in range(max_steps):\n",
    "  1. Assign each point to its closest centroid.\n",
    "  2. Pick new centroids using the members in each cluster. If the centroids don't change, then return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2a1eb",
   "metadata": {},
   "source": [
    "__Is this guaranteed to converge?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f5ac1",
   "metadata": {},
   "source": [
    "## The 'hyperparameters'\n",
    "\n",
    "Things a data scientist can do to influence the k-means clustering (by __looking at the data__):\n",
    "* choose distance metric\n",
    "* choose $k$\n",
    "* choose starting points, or subset of data from which starting points should come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d422dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a distance metric; which one is this??\n",
    "def distance(a, b):\n",
    "    subtracted = a-b\n",
    "    return np.sqrt(np.dot(subtracted.T, subtracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to calculate the distance from each data point to each centroid\n",
    "def get_distances(item, centroids):\n",
    "    distances = [distance(item, centroid) for centroid in centroids]\n",
    "    return distances\n",
    "\n",
    "# Let's define a function to update cluster assignments given a set of centroids\n",
    "def update_clusters(data, centroids):\n",
    "    return [np.argmin(get_distances(item, centroids)) for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to get all the data points assigned to a cluster\n",
    "def get_points_in_cluster(data, clusters, clusterid):\n",
    "    return [data[j] for j in range(len(clusters)) if clusters[j] == clusterid]\n",
    "   \n",
    "# Let's define a function to update the centroids\n",
    "def update_centroids(data, k, clusters):\n",
    "    return np.array([np.mean(get_points_in_cluster(data, clusters, j), axis=0) for j in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b915fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to measure the inertia\n",
    "def inertia(data, centroids, clusters):\n",
    "    sum_squares = 0\n",
    "    for i in range(len(data)):\n",
    "        sum_squares += distance(data[i], centroids[clusters[i]])**2\n",
    "    return sum_squares / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e471169",
   "metadata": {},
   "source": [
    "## Let's try it on some toy data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbe23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get some toy data\n",
    "data = np.array([[1, 1], [2, 0.5], [1.5, 2], [3, 1.5], [3.5, 1.75], [4, 3.6], [4.25, 4], [5, 3.5]])\n",
    "\n",
    "# Let's look at the data\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusters(data, clusters, centroids):\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=clusters)\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        plt.scatter(centroid[0], centroid[1], marker=i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick k = 2\n",
    "k = 2\n",
    "\n",
    "# Let's pick k points to be centroids, at random\n",
    "centroidids = np.random.choice(np.arange(len(data)), size=k, replace=False)\n",
    "centroids = [data[x] for x in centroidids]\n",
    "print(\"initial centroids\")\n",
    "print(centroids)\n",
    "\n",
    "# Initially, only the centroids are in any cluster\n",
    "clusters = update_clusters(data, centroids)\n",
    "print(clusters)\n",
    "plotClusters(data, clusters, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's loop over updating the centroids and plotting\n",
    "while input() != 'stop':\n",
    "    centroids = update_centroids(data, k, clusters)\n",
    "    print(centroids)\n",
    "    clusters = update_clusters(data, centroids)\n",
    "    print(clusters)\n",
    "    print(inertia(data, centroids, clusters))\n",
    "    plotClusters(data, clusters, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594f75e",
   "metadata": {},
   "source": [
    "## Choosing k\n",
    "\n",
    "K nearest neighbors can be frustrating, especially with high dimensional data, because you have to choose a value for k. How can you do it, if you can't visualize all the data?\n",
    "\n",
    "You can inspect an elbow plot of inertia against k, starting with a small k and increasing.\n",
    "\n",
    "Even if you use this method, it's still important to __look at your data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_by_k = np.array([])\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(inertia_by_k[:, 1])\n",
    "ax1.set_xlabel('k')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3b973",
   "metadata": {},
   "source": [
    "## Let's try it on the digits data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e307abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "data = np.array(np.genfromtxt('data/optdigits/optdigits.tra', delimiter=',', dtype=int)) \n",
    "# If we want, we can also make it smaller - to see better. Let's prune to just the numbers 0 through 6\n",
    "data = data[data[:,64]<6,:]\n",
    "# And just the first 500 rows\n",
    "data = data[:500]\n",
    "print(uf.getShapeType(data))\n",
    "print(uf.getSummaryStatistics(data))\n",
    "\n",
    "# Why am I removing the labels?\n",
    "(data, y) = uf.split(data, data.shape[1]-1)\n",
    "\n",
    "# For the purposes of visualization, I'm going to use PCA to reduce this dataset to 3 dimensions\n",
    "data = uf.preprocess(data, zscore=True)\n",
    "eigenvals, eigenvecs = uf.pca_with_plots(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b86055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.validators.scatter.marker import SymbolValidator\n",
    "\n",
    "def project_and_plot_centroids(fig, centroids, eigenvecs, project=True):\n",
    "    if project:\n",
    "        v = eigenvecs[:, :3]\n",
    "        projected_centroids = centroids@v\n",
    "    else:\n",
    "        projected_centroids = centroids\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=projected_centroids[:, 0], y=projected_centroids[:, 1], z=projected_centroids[:, 2], mode='markers'))   \n",
    "    fig.show()\n",
    "    \n",
    "def project_and_plot_data(data, labels, clusters, eigenvecs, project=True):\n",
    "    if project:\n",
    "        v = eigenvecs[:, :3]\n",
    "        projected = data@v\n",
    "    else:\n",
    "        projected = data\n",
    "\n",
    "    projected_with_labels = np.hstack((projected, np.array([labels, clusters]).T))\n",
    "    vals = {0.0: 'circle-open', 1.0: 'cross', 2.0: 'square', 3.0: 'square-open', 4.0: 'diamond', 5.0: 'diamond-open'}\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(x=projected_with_labels[:, 0], y=projected_with_labels[:, 1], z=projected_with_labels[:, 2], mode='markers', marker=dict(size=8, symbol=[vals[(int(x))] for x in projected_with_labels[:, 4]], color=projected_with_labels[:, 3])))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a2fec",
   "metadata": {},
   "source": [
    "### Six clusters, random initialization\n",
    "\n",
    "Why six?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "\n",
    "# Let's pick k points to be centroids, at random\n",
    "centroidids = np.random.choice(np.arange(len(data)), size=k, replace=False)\n",
    "centroids = np.array([data[x] for x in centroidids])\n",
    "\n",
    "clusters = update_clusters(data, centroids)\n",
    "fig = project_and_plot_data(data, y, clusters, eigenvecs)\n",
    "project_and_plot_centroids(fig, centroids, eigenvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's loop over updating the centroids and plotting\n",
    "while input() != 'stop':\n",
    "    centroids = update_centroids(data, k, clusters)\n",
    "    clusters = update_clusters(data, centroids)\n",
    "    print(inertia(data, centroids, clusters))\n",
    "    fig = project_and_plot_data(data, y, clusters, eigenvecs)\n",
    "    project_and_plot_centroids(fig, centroids, eigenvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2918801",
   "metadata": {},
   "source": [
    "### Six clusters, non-random initialization\n",
    "\n",
    "What if I could borrow 10 minutes of your time to label 20 data points, and could use them as the starting centroids?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroidids = np.array([0, 11, 5, 14, 3, 6])\n",
    "centroids = [data[x] for x in centroidids]\n",
    "\n",
    "clusters = update_clusters(data, centroids)\n",
    "fig = project_and_plot_data(data, y, clusters, eigenvecs)\n",
    "project_and_plot_centroids(fig, centroids, eigenvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8dac9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's loop over updating the centroids and plotting\n",
    "while input() != 'stop':\n",
    "    centroids = update_centroids(data, k, clusters)\n",
    "    clusters = update_clusters(data, centroids)\n",
    "    print(inertia(data, centroids, clusters))\n",
    "    fig = project_and_plot_data(data, y, clusters, eigenvecs)\n",
    "    project_and_plot_centroids(fig, centroids, eigenvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a92ce",
   "metadata": {},
   "source": [
    "### In PCA space\n",
    "\n",
    "... Mostly just for the heck of it :)\n",
    "\n",
    "BUT if your variables have very different ranges you *must* normalize, or the large-range variables will dominate the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = eigenvecs[:, :3]\n",
    "projected = data@v\n",
    "\n",
    "# Let's pick 10 at random\n",
    "centroidids = np.random.choice(np.arange(len(projected)), size=k, replace=False)\n",
    "centroids = np.array([projected[x] for x in centroidids])\n",
    "\n",
    "clusters = update_clusters(projected, centroids)\n",
    "fig = project_and_plot_data(projected, y, clusters, eigenvecs, project=False)\n",
    "project_and_plot_centroids(fig, centroids, eigenvecs, project=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57223281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's loop over updating the centroids and plotting\n",
    "while input() != 'stop':\n",
    "    centroids = update_centroids(projected, k, clusters)\n",
    "    clusters = update_clusters(projected, centroids)\n",
    "    \n",
    "    print(inertia(projected, centroids, clusters))\n",
    "    fig = project_and_plot_data(projected, y, clusters, eigenvecs, project=False)\n",
    "    project_and_plot_centroids(fig, centroids, eigenvecs, project=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4c628",
   "metadata": {},
   "source": [
    "Of course, we want to know how good our clusters are. How can we figure that out? \n",
    "\n",
    "As an initial stab, *since we have labels*, let's go through label by label and see how many clusters are assigned to the data with each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538737bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_with_labels = np.hstack((data, np.array([y, clusters]).T))\n",
    "print(projected_with_labels.shape)\n",
    "for label in range(6):\n",
    "    subset = projected_with_labels[projected_with_labels[:,64]==label,:]\n",
    "    print(label, subset.shape, np.unique(subset[:, 65], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64683bfb",
   "metadata": {},
   "source": [
    "What does this tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130dd92",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* For a list of lots of clustering algorithms, see https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59753cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
